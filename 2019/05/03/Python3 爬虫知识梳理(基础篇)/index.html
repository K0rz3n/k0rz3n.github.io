

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/icon/warning.png">
  <link rel="icon" href="/img/icon/warning.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="0X01 常用的 python 库1.urllibimport urllib import urllib.request urllib.request.urlopen(&quot;http:&#x2F;&#x2F;www.baidu.com&quot;)  2.re3.requests4.selenimu这个库是配合一些驱动去爬取动态渲染网页的库">
<meta property="og:type" content="article">
<meta property="og:title" content="Python3 爬虫知识梳理(基础篇)">
<meta property="og:url" content="http://example.com/2019/05/03/Python3%20%E7%88%AC%E8%99%AB%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86(%E5%9F%BA%E7%A1%80%E7%AF%87)/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="0X01 常用的 python 库1.urllibimport urllib import urllib.request urllib.request.urlopen(&quot;http:&#x2F;&#x2F;www.baidu.com&quot;)  2.re3.requests4.selenimu这个库是配合一些驱动去爬取动态渲染网页的库">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://picture-1253331270.cos.ap-beijing.myqcloud.com/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%801.png">
<meta property="og:image" content="https://picture-1253331270.cos.ap-beijing.myqcloud.com/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%802.png">
<meta property="article:published_time" content="2019-05-03T15:49:18.000Z">
<meta property="article:modified_time" content="2025-01-24T15:19:08.588Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="爬虫">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://picture-1253331270.cos.ap-beijing.myqcloud.com/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%801.png">
  
  
  
  <title>Python3 爬虫知识梳理(基础篇) - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/css/macpanel.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 60vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>K0rz3n&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/banner/icemountain.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Python3 爬虫知识梳理(基础篇)"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2019-05-03 16:49" pubdate>
          May 3, 2019 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          16k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          134 mins
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">Python3 爬虫知识梳理(基础篇)</h1>
            
            
              <div class="markdown-body">
                
                <h2 id="0X01-常用的-python-库"><a href="#0X01-常用的-python-库" class="headerlink" title="0X01 常用的 python 库"></a><strong>0X01 常用的 python 库</strong></h2><h3 id="1-urllib"><a href="#1-urllib" class="headerlink" title="1.urllib"></a><strong>1.urllib</strong></h3><pre><code class="hljs">import urllib
import urllib.request
urllib.request.urlopen(&quot;http://www.baidu.com&quot;)
</code></pre>
<h3 id="2-re"><a href="#2-re" class="headerlink" title="2.re"></a><strong>2.re</strong></h3><h3 id="3-requests"><a href="#3-requests" class="headerlink" title="3.requests"></a><strong>3.requests</strong></h3><h3 id="4-selenimu"><a href="#4-selenimu" class="headerlink" title="4.selenimu"></a><strong>4.selenimu</strong></h3><p>这个库是配合一些驱动去爬取动态渲染网页的库</p>
<span id="more"></span>

<h4 id="1-chromedriver"><a href="#1-chromedriver" class="headerlink" title="(1)chromedriver"></a><strong>(1)chromedriver</strong></h4><p>我们使用的时候需要先下载一个 <a target="_blank" rel="noopener" href="http://npm.taobao.org/mirrors/chromedriver/2.46/">chromedriver.exe</a> ，下载好了以后放在 chrome.exe 的相同目录下（默认安装路径），然后将这个目录放作为 PATH</p>
<pre><code class="hljs">import selenium
from selenium import webdriver

driver = webdriver.Chrome()
driver.get(&quot;http://www.baidu.com&quot;)
driver.page_source
</code></pre>
<p>这种方式的唯一的缺点是会出现浏览器界面，这可能是我们不需要的,所以我们可以使用 headless 的方式来隐藏 web 界面(其实就是使用 options() 对象的 add_argument 属性去设置 headless 参数 )</p>
<pre><code class="hljs">import os
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.options import Options
import time

chrome_options = Options()
chrome_options.add_argument(&quot;--headless&quot;)

base_url = &quot;http://www.baidu.com/&quot;
#对应的chromedriver的放置目录
driver = webdriver.Chrome(executable_path=(r&#39;C:\Program Files (x86)\Google\Chrome\Application\chromedriver.exe&#39;), chrome_options=chrome_options)

driver.get(base_url + &quot;/&quot;)

start_time=time.time()
print(&#39;this is start_time &#39;,start_time)

driver.find_element_by_id(&quot;kw&quot;).send_keys(&quot;selenium webdriver&quot;)
driver.find_element_by_id(&quot;su&quot;).click()
driver.save_screenshot(&#39;screen.png&#39;)

driver.close()

end_time=time.time()
print(&#39;this is end_time &#39;,end_time)
</code></pre>
<h4 id="2-phantomJS"><a href="#2-phantomJS" class="headerlink" title="(2)phantomJS"></a><strong>(2)phantomJS</strong></h4><p>这是另一种无界面的实现方法，虽然说不维护了，并且在使用的过程中会出现各种玄学，但是还是要介绍一下</p>
<p>和 Chromedriver 一样，我们首先要去<a target="_blank" rel="noopener" href="http://phantomjs.org/download.html">下载</a> phantomJS,然后将其放在 PATH 中方便我们后面的调用</p>
<pre><code class="hljs">import selenium
from selenium import webdriver

driver = webdriver.phantomJS()
driver.get(&quot;http://www.baidu.com&quot;)
driver.page_source
</code></pre>
<h3 id="5-lxml"><a href="#5-lxml" class="headerlink" title="5.lxml"></a><strong>5.lxml</strong></h3><p>这个是为 XPATH 的使用准备的库</p>
<h3 id="6-beautifulsoup"><a href="#6-beautifulsoup" class="headerlink" title="6.beautifulsoup"></a><strong>6.beautifulsoup</strong></h3><p>pip 安装的时候注意一下要安装 beautifulsoup4,表示第四个版本，并且这个库是依赖于 lxml 的，所以安装之前请先安装 lxml </p>
<pre><code class="hljs">from bs4 import BeautifulSoup
soup = BeautifulSoup(&#39;`&lt;html&gt;&lt;/html&gt;&#39;,&#39;lxml&#39;)
</code></pre>
<h3 id="7-pyquery"><a href="#7-pyquery" class="headerlink" title="7.pyquery"></a><strong>7.pyquery</strong></h3><p>和 BeautifulSoup 一样也是一个网页解析库，但是相对来讲语法简单一些（语法是模仿 jQuery 的）</p>
<pre><code class="hljs">from pyquery import PyQuery as pq

page = pq(&#39;`&lt;html&gt;hello world&lt;/html&gt;`&#39;)
result = page(&#39;html&#39;).text()
result
</code></pre>
<h3 id="8-pymysql"><a href="#8-pymysql" class="headerlink" title="8.pymysql"></a><strong>8.pymysql</strong></h3><p>这个库是 py 操纵 Mysql 的库</p>
<pre><code class="hljs">import pymysql

conn = pymysql.connect(host=&#39;localhost&#39;,user=&#39;root&#39;,password=&#39;root&#39;,port=3306,db=&#39;test&#39;)
cursor = conn.cursor()
result = cursor.execute(&#39;select * from user where id = 1&#39;)
print(cursor.fetchone())
</code></pre>
<h3 id="9-pymango"><a href="#9-pymango" class="headerlink" title="9.pymango"></a><strong>9.pymango</strong></h3><pre><code class="hljs">import pymango

client = pymango.MongoClient(&#39;localhost&#39;)
db = client(&#39;newtestdb&#39;)
db[&#39;table&#39;].insert(&#123;&#39;name&#39;:&#39;Bob&#39;&#125;)
db[&#39;table&#39;].find_one(&#123;&#39;name&#39;:&#39;Bob&#39;&#125;)
</code></pre>
<h3 id="10-redis"><a href="#10-redis" class="headerlink" title="10.redis"></a><strong>10.redis</strong></h3><pre><code class="hljs">import redis

r = redis.Redis(&#39;localhost&#39;,6379)
r.set(&quot;name&quot;,&quot;Bob&quot;)
r.get(&#39;name&#39;)
</code></pre>
<h3 id="11-flask"><a href="#11-flask" class="headerlink" title="11.flask"></a><strong>11.flask</strong></h3><p>flask 在后期使用代理的时候可能会用到</p>
<pre><code class="hljs">from flask import Flask

app = Flask(__name__)

@app.route(&#39;/&#39;)

def hello():
	return &quot;hello world&quot;

if __name__ == &#39;__main__&#39;:
	
    app.run(debug=True)
</code></pre>
<h3 id="12-django"><a href="#12-django" class="headerlink" title="12.django"></a><strong>12.django</strong></h3><p>在分布式爬虫的维护方面可能会用到 django </p>
<h3 id="13-jupyter"><a href="#13-jupyter" class="headerlink" title="13.jupyter"></a><strong>13.jupyter</strong></h3><p>网页端记事本</p>
<h2 id="0X02-基础部分"><a href="#0X02-基础部分" class="headerlink" title="0X02 基础部分"></a><strong>0X02 基础部分</strong></h2><h3 id="1-爬虫基本原理"><a href="#1-爬虫基本原理" class="headerlink" title="1.爬虫基本原理"></a><strong>1.爬虫基本原理</strong></h3><h4 id="1-爬虫是什么"><a href="#1-爬虫是什么" class="headerlink" title="(1)爬虫是什么"></a><strong>(1)爬虫是什么</strong></h4><p>爬虫就是请求网页并且提取数据的自动化工具</p>
<h4 id="2-爬虫的基本流程"><a href="#2-爬虫的基本流程" class="headerlink" title="(2)爬虫的基本流程"></a><strong>(2)爬虫的基本流程</strong></h4><h5 id="1-发起请求："><a href="#1-发起请求：" class="headerlink" title="1.发起请求："></a><strong>1.发起请求：</strong></h5><p>通过 HTTP 库向目标网站发起请求，即发送一个 request（可以包含额外的header信息），然后等待服务器的响应</p>
<h5 id="2-获取响应内容"><a href="#2-获取响应内容" class="headerlink" title="2.获取响应内容"></a><strong>2.获取响应内容</strong></h5><p>如果服务器正常响应，会得到一个 Response.其内容就是所要获取的页面的内容，类型可以是 HTML、JSON、二进制数据(图片视频)等</p>
<h5 id="3-解析内容"><a href="#3-解析内容" class="headerlink" title="3.解析内容"></a><strong>3.解析内容</strong></h5><p>对 HTML 数据可以使用正则表达式、网页解析库进行解析。如果是 Json 则可以转化成 JSON 对象解析，如果是二进制数据可以保存或者进一步处理</p>
<h5 id="4-保存数据"><a href="#4-保存数据" class="headerlink" title="4.保存数据"></a><strong>4.保存数据</strong></h5><p>保存的形式多样，可以是纯文本，也可以保存成数据库，或者保存为特定格式的文件</p>
<h4 id="3-请求的基本元素"><a href="#3-请求的基本元素" class="headerlink" title="(3)请求的基本元素"></a><strong>(3)请求的基本元素</strong></h4><p>1.请求方法<br>2.请求 URL<br>3.请求头<br>4.请求体(POST 方法独有)</p>
<h4 id="4-请响应的基本元素"><a href="#4-请响应的基本元素" class="headerlink" title="(4)请响应的基本元素"></a><strong>(4)请响应的基本元素</strong></h4><p>1.状态码<br>2.响应头<br>3.响应体</p>
<h4 id="5-实例代码："><a href="#5-实例代码：" class="headerlink" title="(5)实例代码："></a><strong>(5)实例代码：</strong></h4><h5 id="1-请求网页数据"><a href="#1-请求网页数据" class="headerlink" title="1.请求网页数据"></a><strong>1.请求网页数据</strong></h5><pre><code class="hljs">import requests

headers = &#123;&#39;User-Agent&#39;:&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36&#39;&#125;
res = requests.get(&quot;http://www.baidu.com&quot;,headers=headers)

print(res.status_code)
print(res.headers)
print(res.text)
</code></pre>
<p>当然这里使用的是 res.text 这种文本格式，如果返回的是一个二进制格式的数据(比如图片)，那么我们应该使用 res.content</p>
<h5 id="2-请求二进制数据"><a href="#2-请求二进制数据" class="headerlink" title="2.请求二进制数据"></a><strong>2.请求二进制数据</strong></h5><pre><code class="hljs">import requests

headers = &#123;&#39;User-Agent&#39;:&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36&#39;&#125;
res = requests.get(&quot;https://ss2.bdstatic.com/lfoZeXSm1A5BphGlnYG/icon/95486.png&quot;,headers=headers)
print(res.content)

with open(r&#39;E:\桌面\1.png&#39;,&#39;wb&#39;) as f:
	f.write(res.content)
	f.close()
</code></pre>
<h4 id="6-解析方式"><a href="#6-解析方式" class="headerlink" title="(6)解析方式"></a><strong>(6)解析方式</strong></h4><p>1.直接处理<br>2.转化成 json对象<br>3.正则匹配<br>4.BeautifulSoap<br>5.PyQuery<br>6.XPath</p>
<h4 id="7-response-的结果为什么和浏览器中的看到的不同"><a href="#7-response-的结果为什么和浏览器中的看到的不同" class="headerlink" title="(7)response 的结果为什么和浏览器中的看到的不同"></a><strong>(7)response 的结果为什么和浏览器中的看到的不同</strong></h4><p>我们使用脚本去请求(只是一次请求)网页得到的是最原始的网页的源码，这个源码里面会有很多的远程的 js 和 css 的加载，我们的脚本是没法解析的，但是浏览器能对这些远程的链接进行再次的请求，然后利用加载到的数据对页面进行进一步的加载和渲染，于是我们在浏览器中看到的页面是很多请求渲染得到的结果，因此和我们一次请求的到的页面肯定是不一样的。</p>
<h4 id="8-如何解决-JS-渲染的问题"><a href="#8-如何解决-JS-渲染的问题" class="headerlink" title="(8)如何解决 JS 渲染的问题"></a><strong>(8)如何解决 JS 渲染的问题</strong></h4><p>解决问题的方法本质上就是模拟浏览器的加载渲染，然后将渲染好的页面进行返回</p>
<p>1.分析Ajax 请求<br>2.selenium+webdriver(推荐)<br>3.splash<br>4.PyV8、Ghostpy</p>
<h4 id="9-如何存储数据"><a href="#9-如何存储数据" class="headerlink" title="(9)如何存储数据"></a><strong>(9)如何存储数据</strong></h4><p>1.纯本文<br>2.关系型数据库<br>3.非关系型数据库<br>4.二进制文件</p>
<h2 id="0X03-Urllib-库"><a href="#0X03-Urllib-库" class="headerlink" title="0X03 Urllib 库"></a><strong>0X03 Urllib 库</strong></h2><h3 id="1-什么是-Urllib-库"><a href="#1-什么是-Urllib-库" class="headerlink" title="1.什么是 Urllib 库"></a><strong>1.什么是 Urllib 库</strong></h3><p>这个库是 python 的内置的一个请求库</p>
<p>urllib.request —————–&gt;请求模块<br>urllib.error——————–&gt;异常处理模块<br>urllib.parse——————–&gt;url解析模块<br>urllib.robotparser  ————&gt;robots.txt 解析模块</p>
<h3 id="2-urllib-库的基本使用"><a href="#2-urllib-库的基本使用" class="headerlink" title="2.urllib 库的基本使用"></a><strong>2.urllib 库的基本使用</strong></h3><h4 id="1-函数调用原型"><a href="#1-函数调用原型" class="headerlink" title="(1)函数调用原型"></a><strong>(1)函数调用原型</strong></h4><pre><code class="hljs">urllib.request.urlopen(url,data,timeout...)
</code></pre>
<h4 id="2-实例代码一：GET-请求"><a href="#2-实例代码一：GET-请求" class="headerlink" title="(2)实例代码一：GET 请求"></a><strong>(2)实例代码一：GET 请求</strong></h4><pre><code class="hljs">import urllib.request

res = urllib.request.urlopen(&quot;http://www.baidu.com&quot;)
print(res.read().decode(&#39;utf-8&#39;))
</code></pre>
<h4 id="3-实例代码二：POST-请求"><a href="#3-实例代码二：POST-请求" class="headerlink" title="(3)实例代码二：POST 请求"></a><strong>(3)实例代码二：POST 请求</strong></h4><pre><code class="hljs">import urllib.request
import urllib.parse
from pprint import pprint

data = bytes(urllib.parse.urlencode(&#123;&#39;world&#39;:&#39;hello&#39;&#125;),encoding = &#39;utf8&#39;)
res = urllib.request.urlopen(&#39;https://httpbin.org/post&#39;,data = data)
pprint(res.read().decode(&#39;utf-8&#39;))
</code></pre>
<h4 id="4-实例代码三：超时设置"><a href="#4-实例代码三：超时设置" class="headerlink" title="(4)实例代码三：超时设置"></a><strong>(4)实例代码三：超时设置</strong></h4><pre><code class="hljs">import urllib.request

res = urllib.request.urlopen(&quot;http://httpbin.org.get&quot;,timeout = 1)
print(res.read().decode(&#39;utf-8&#39;))
</code></pre>
<h4 id="5-实例代码：获取响应状态码、响应头、响应体"><a href="#5-实例代码：获取响应状态码、响应头、响应体" class="headerlink" title="(5)实例代码：获取响应状态码、响应头、响应体"></a><strong>(5)实例代码：获取响应状态码、响应头、响应体</strong></h4><pre><code class="hljs">import urllib.request

res = urllib.request.urlopen(&quot;http://httpbin.org/get&quot;)
print(res.status)
print(res.getheaders())
print(res.getheader(&#39;Server&#39;))
#获取响应体的使用 read() 的结果是 Bytes 类型，我们还要用 decode(&#39;utf-8&#39;)转化成字符串
print(res.read().decode(&#39;utf-8&#39;))
</code></pre>
<h4 id="6-request-对象"><a href="#6-request-对象" class="headerlink" title="(6) request 对象"></a><strong>(6) request 对象</strong></h4><pre><code class="hljs">from urllib import request,parse
from pprint import pprint

url = &quot;https://httpbin.org/post&quot;
headers = &#123;
    &#39;User-Agent&#39;:&#39;hello wolrd&#39;,
    &#39;Host&#39;:&#39;httpbin.org&#39;
&#125;
dict = &#123;
    &#39;name&#39;:&#39;Tom&#39;,
&#125;

data = bytes(parse.urlencode(dict),encoding=&#39;utf8&#39;)
req = request.Request(url=url,data=data,headers=headers,method=&#39;POST&#39;)
res = request.urlopen(req)
pprint(res.read().decode(&#39;utf-8&#39;))
</code></pre>
<h3 id="3-urllib-库的进阶使用"><a href="#3-urllib-库的进阶使用" class="headerlink" title="3.urllib 库的进阶使用"></a><strong>3.urllib 库的进阶使用</strong></h3><h4 id="1-代理"><a href="#1-代理" class="headerlink" title="(1)代理"></a><strong>(1)代理</strong></h4><pre><code class="hljs">import urllib.request

proxy_handler = urllib.request.ProxyHandler(&#123;
    &#39;http&#39;:&#39;http://127.0.0.1:9743&#39;
&#125;)

opener = urllib.request.build_opener(proxy_handler)
res = opener.open(&#39;https://www.taobao.com&#39;)
print(res.read())
</code></pre>
<h4 id="2-Cookie"><a href="#2-Cookie" class="headerlink" title="(2)Cookie"></a><strong>(2)Cookie</strong></h4><h5 id="1-获取-cookies"><a href="#1-获取-cookies" class="headerlink" title="1.获取 cookies"></a><strong>1.获取 cookies</strong></h5><pre><code class="hljs">import http.cookiejar
import urllib.request

cookie = http.cookiejar.CookieJar()
handler = urllib.request.HTTPCookieProcessor(cookie)
opener = urllib.request.build_opener(handler)
response = opener.open(&quot;http://www.baidu.com&quot;)
for item in cookie:
    print(item.name+&quot;=&quot;+item.value)
</code></pre>
<h5 id="2-将-cookie-保存成文本文件"><a href="#2-将-cookie-保存成文本文件" class="headerlink" title="2.将 cookie 保存成文本文件"></a><strong>2.将 cookie 保存成文本文件</strong></h5><p><strong>格式一：</strong></p>
<pre><code class="hljs">import http.cookiejar, urllib.request
filename = &quot;cookie.txt&quot;
cookie = http.cookiejar.MozillaCookieJar(filename)
handler = urllib.request.HTTPCookieProcessor(cookie)
opener = urllib.request.build_opener(handler)
response = opener.open(&#39;http://www.baidu.com&#39;)
cookie.save(ignore_discard=True, ignore_expires=True)
</code></pre>
<p><strong>格式二：</strong></p>
<pre><code class="hljs">import http.cookiejar, urllib.request
filename = &#39;cookie.txt&#39;
cookie = http.cookiejar.LWPCookieJar(filename)
handler = urllib.request.HTTPCookieProcessor(cookie)
opener = urllib.request.build_opener(handler)
response = opener.open(&#39;http://www.baidu.com&#39;)
cookie.save(ignore_discard=True, ignore_expires=True)
</code></pre>
<h5 id="3-使用文件中的-cookie"><a href="#3-使用文件中的-cookie" class="headerlink" title="3.使用文件中的 cookie"></a><strong>3.使用文件中的 cookie</strong></h5><pre><code class="hljs">import http.cookiejar, urllib.request
cookie = http.cookiejar.LWPCookieJar()
cookie.load(&#39;cookie.txt&#39;, ignore_discard=True, ignore_expires=True)
handler = urllib.request.HTTPCookieProcessor(cookie)
opener = urllib.request.build_opener(handler)
response = opener.open(&#39;http://www.baidu.com&#39;)
print(response.read().decode(&#39;utf-8&#39;))
</code></pre>
<h4 id="3-异常处理"><a href="#3-异常处理" class="headerlink" title="(3)异常处理"></a><strong>(3)异常处理</strong></h4><h5 id="1-实例代码一：URLError"><a href="#1-实例代码一：URLError" class="headerlink" title="1.实例代码一：URLError"></a><strong>1.实例代码一：URLError</strong></h5><pre><code class="hljs">from urllib import request
from urllib import error

try:
    urllib.request.urlopen(&quot;http://httpbin.org/xss&quot;)
except error.URLError as e:
    print(e.reason)
</code></pre>
<h5 id="2-实例代码二：HTTPError"><a href="#2-实例代码二：HTTPError" class="headerlink" title="2.实例代码二：HTTPError"></a><strong>2.实例代码二：HTTPError</strong></h5><pre><code class="hljs">from urllib import request, error

try:
    response = request.urlopen(&#39;http://httpbin.org/xss&#39;)
except error.HTTPError as e:
    print(e.reason, e.code, e.headers, sep=&#39;\n&#39;)
except error.URLError as e:
    print(e.reason)
else:
    print(&#39;Request Successfully&#39;)
</code></pre>
<h5 id="3-实例代码三：异常类型判断"><a href="#3-实例代码三：异常类型判断" class="headerlink" title="3.实例代码三：异常类型判断"></a><strong>3.实例代码三：异常类型判断</strong></h5><pre><code class="hljs">import socket
import urllib.request
import urllib.error

try:
    response = urllib.request.urlopen(&#39;https://www.baidu.com&#39;, timeout=0.01)
except urllib.error.URLError as e:
    print(type(e.reason))
    if isinstance(e.reason, socket.timeout):
        print(&#39;TIME OUT&#39;)
</code></pre>
<h4 id="4-URL-解析工具类"><a href="#4-URL-解析工具类" class="headerlink" title="(4)URL 解析工具类"></a><strong>(4)URL 解析工具类</strong></h4><h5 id="1-urlparse"><a href="#1-urlparse" class="headerlink" title="1.urlparse"></a><strong>1.urlparse</strong></h5><pre><code class="hljs">from urllib.parse import urlparse

result = urlparse(&#39;http://www.baidu.com/index.html;user?id=5#comment&#39;)
print(type(result), result)
</code></pre>
<h5 id="2-urlunparse"><a href="#2-urlunparse" class="headerlink" title="2.urlunparse"></a><strong>2.urlunparse</strong></h5><pre><code class="hljs">from urllib.parse import urlunparse

data = [&#39;http&#39;, &#39;www.baidu.com&#39;, &#39;index.html&#39;, &#39;user&#39;, &#39;a=6&#39;, &#39;comment&#39;]
print(urlunparse(data))
</code></pre>
<h5 id="3-urljoin"><a href="#3-urljoin" class="headerlink" title="3.urljoin"></a><strong>3.urljoin</strong></h5><pre><code class="hljs">from urllib.parse import urljoin

print(urljoin(&#39;http://www.baidu.com&#39;, &#39;FAQ.html&#39;))
</code></pre>
<h5 id="4-urlencode"><a href="#4-urlencode" class="headerlink" title="4.urlencode"></a><strong>4.urlencode</strong></h5><pre><code class="hljs">from urllib.parse import urlencode

params = &#123;
    &#39;name&#39;: &#39;germey&#39;,
    &#39;age&#39;: 22
&#125;
base_url = &#39;http://www.baidu.com?&#39;
url = base_url + urlencode(params)
print(url)
</code></pre>
<h2 id="0X04-Requests-库"><a href="#0X04-Requests-库" class="headerlink" title="0X04 Requests 库"></a><strong>0X04 Requests 库</strong></h2><h3 id="1-什么是-requests-库"><a href="#1-什么是-requests-库" class="headerlink" title="1.什么是 requests 库"></a><strong>1.什么是 requests 库</strong></h3><p>这个库是基于 URLlib3 的，改善了 urllib api 比较繁琐的特点，使用几句简单的语句就能实现设置 cookie 和设置代理的功能，非常的方便</p>
<h3 id="2-requests-库的基本使用"><a href="#2-requests-库的基本使用" class="headerlink" title="2.requests 库的基本使用"></a><strong>2.requests 库的基本使用</strong></h3><h4 id="1-获取响应信息"><a href="#1-获取响应信息" class="headerlink" title="(1)获取响应信息"></a><strong>(1)获取响应信息</strong></h4><pre><code class="hljs">import requests

res = requests.get(&quot;http://www.baidu.com&quot;)
print(res.status_code)
print(res.text)
print(res.cookies)
</code></pre>
<h4 id="2-各种请求方法"><a href="#2-各种请求方法" class="headerlink" title="(2)各种请求方法"></a><strong>(2)各种请求方法</strong></h4><pre><code class="hljs">import requests

requests.get(&quot;http://httpbin.org/get&quot;)
requests.post(&quot;http://httpbin.org/post&quot;)
requests.put(&quot;http://httpbin.org/put&quot;)
requests.head(&quot;http://httpbin.org/get&quot;)
requests.delete(&quot;http://httpbin.org/delete&quot;)
requests.options(&quot;http://httpbin.org/get&quot;)
</code></pre>
<h4 id="3-带参数的-get-请求"><a href="#3-带参数的-get-请求" class="headerlink" title="(3)带参数的 get 请求"></a><strong>(3)带参数的 get 请求</strong></h4><pre><code class="hljs">import requests

params = &#123;
    &#39;id&#39;:1,
    &#39;user&#39;:&#39;Tom&#39;,
    &#39;pass&#39;:&#39;123456&#39;
&#125;

res = requests.get(&#39;http://httpbin.org/get&#39;,params = params )
print(res.text)
</code></pre>
<h4 id="4-解析-json"><a href="#4-解析-json" class="headerlink" title="(4)解析 json"></a><strong>(4)解析 json</strong></h4><pre><code class="hljs">import requests

res = requests.get(&quot;http://httpbin.org/get&quot;)
print(res.json())
</code></pre>
<h4 id="5-获取二进制数据"><a href="#5-获取二进制数据" class="headerlink" title="(5)获取二进制数据"></a><strong>(5)获取二进制数据</strong></h4><pre><code class="hljs">import requests

response = requests.get(&quot;https://github.com/favicon.ico&quot;)
with open(&#39;favicon.ico&#39;, &#39;wb&#39;) as f:
    f.write(response.content)
    f.close()
</code></pre>
<h4 id="6-添加-headers"><a href="#6-添加-headers" class="headerlink" title="(6)添加 headers"></a><strong>(6)添加 headers</strong></h4><pre><code class="hljs">import requests

headers = &#123;
    &#39;User-Agent&#39;: &#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36&#39;
&#125;
response = requests.get(&quot;https://www.zhihu.com/explore&quot;, headers=headers)
print(response.text)
</code></pre>
<h4 id="7-POST-请求"><a href="#7-POST-请求" class="headerlink" title="(7)POST 请求"></a><strong>(7)POST 请求</strong></h4><pre><code class="hljs">import requests

data = &#123;
    &#39;id&#39;:1,
    &#39;user&#39;:&#39;Tom&#39;,
    &#39;pass&#39;:&#39;123456&#39;,
&#125;

res = requests.post(&#39;http://httpbin.org/post&#39;,data=data)
print(res.text)
</code></pre>
<h4 id="8-response-属性"><a href="#8-response-属性" class="headerlink" title="(8) response 属性"></a><strong>(8) response 属性</strong></h4><pre><code class="hljs">import requests

data = &#123;
    &#39;id&#39;:1,
    &#39;user&#39;:&#39;Tom&#39;,
    &#39;pass&#39;:&#39;123456&#39;,
&#125;

res = requests.post(&#39;http://httpbin.org/post&#39;,data=data)
print(res.text)
print(res.status_code)
print(res.headers)
print(res.cookies)
print(res.history)
print(res.url)
</code></pre>
<h4 id="9-响应状态码"><a href="#9-响应状态码" class="headerlink" title="(9)响应状态码"></a><strong>(9)响应状态码</strong></h4><p>每一个状态码都对应着一个名字，我们只要调用这个名字就可以进行判断了</p>
<pre><code class="hljs">100: (&#39;continue&#39;,),
101: (&#39;switching_protocols&#39;,),
102: (&#39;processing&#39;,),
103: (&#39;checkpoint&#39;,),
122: (&#39;uri_too_long&#39;, &#39;request_uri_too_long&#39;),
200: (&#39;ok&#39;, &#39;okay&#39;, &#39;all_ok&#39;, &#39;all_okay&#39;, &#39;all_good&#39;, &#39;\\o/&#39;, &#39;✓&#39;),
201: (&#39;created&#39;,),
202: (&#39;accepted&#39;,),
203: (&#39;non_authoritative_info&#39;, &#39;non_authoritative_information&#39;),
204: (&#39;no_content&#39;,),
205: (&#39;reset_content&#39;, &#39;reset&#39;),
206: (&#39;partial_content&#39;, &#39;partial&#39;),
207: (&#39;multi_status&#39;, &#39;multiple_status&#39;, &#39;multi_stati&#39;, &#39;multiple_stati&#39;),
208: (&#39;already_reported&#39;,),
226: (&#39;im_used&#39;,),

# Redirection.
300: (&#39;multiple_choices&#39;,),
301: (&#39;moved_permanently&#39;, &#39;moved&#39;, &#39;\\o-&#39;),
302: (&#39;found&#39;,),
303: (&#39;see_other&#39;, &#39;other&#39;),
304: (&#39;not_modified&#39;,),
305: (&#39;use_proxy&#39;,),
306: (&#39;switch_proxy&#39;,),
307: (&#39;temporary_redirect&#39;, &#39;temporary_moved&#39;, &#39;temporary&#39;),
308: (&#39;permanent_redirect&#39;,
      &#39;resume_incomplete&#39;, &#39;resume&#39;,), # These 2 to be removed in 3.0

# Client Error.
400: (&#39;bad_request&#39;, &#39;bad&#39;),
401: (&#39;unauthorized&#39;,),
402: (&#39;payment_required&#39;, &#39;payment&#39;),
403: (&#39;forbidden&#39;,),
404: (&#39;not_found&#39;, &#39;-o-&#39;),
405: (&#39;method_not_allowed&#39;, &#39;not_allowed&#39;),
406: (&#39;not_acceptable&#39;,),
407: (&#39;proxy_authentication_required&#39;, &#39;proxy_auth&#39;, &#39;proxy_authentication&#39;),
408: (&#39;request_timeout&#39;, &#39;timeout&#39;),
409: (&#39;conflict&#39;,),
410: (&#39;gone&#39;,),
411: (&#39;length_required&#39;,),
412: (&#39;precondition_failed&#39;, &#39;precondition&#39;),
413: (&#39;request_entity_too_large&#39;,),
414: (&#39;request_uri_too_large&#39;,),
415: (&#39;unsupported_media_type&#39;, &#39;unsupported_media&#39;, &#39;media_type&#39;),
416: (&#39;requested_range_not_satisfiable&#39;, &#39;requested_range&#39;, &#39;range_not_satisfiable&#39;),
417: (&#39;expectation_failed&#39;,),
418: (&#39;im_a_teapot&#39;, &#39;teapot&#39;, &#39;i_am_a_teapot&#39;),
421: (&#39;misdirected_request&#39;,),
422: (&#39;unprocessable_entity&#39;, &#39;unprocessable&#39;),
423: (&#39;locked&#39;,),
424: (&#39;failed_dependency&#39;, &#39;dependency&#39;),
425: (&#39;unordered_collection&#39;, &#39;unordered&#39;),
426: (&#39;upgrade_required&#39;, &#39;upgrade&#39;),
428: (&#39;precondition_required&#39;, &#39;precondition&#39;),
429: (&#39;too_many_requests&#39;, &#39;too_many&#39;),
431: (&#39;header_fields_too_large&#39;, &#39;fields_too_large&#39;),
444: (&#39;no_response&#39;, &#39;none&#39;),
449: (&#39;retry_with&#39;, &#39;retry&#39;),
450: (&#39;blocked_by_windows_parental_controls&#39;, &#39;parental_controls&#39;),
451: (&#39;unavailable_for_legal_reasons&#39;, &#39;legal_reasons&#39;),
499: (&#39;client_closed_request&#39;,),

# Server Error.
500: (&#39;internal_server_error&#39;, &#39;server_error&#39;, &#39;/o\\&#39;, &#39;✗&#39;),
501: (&#39;not_implemented&#39;,),
502: (&#39;bad_gateway&#39;,),
503: (&#39;service_unavailable&#39;, &#39;unavailable&#39;),
504: (&#39;gateway_timeout&#39;,),
505: (&#39;http_version_not_supported&#39;, &#39;http_version&#39;),
506: (&#39;variant_also_negotiates&#39;,),
507: (&#39;insufficient_storage&#39;,),
509: (&#39;bandwidth_limit_exceeded&#39;, &#39;bandwidth&#39;),
510: (&#39;not_extended&#39;,),
511: (&#39;network_authentication_required&#39;, &#39;network_auth&#39;, &#39;network_authentication&#39;),
</code></pre>
<p><strong>实例代码：</strong></p>
<pre><code class="hljs">import requests

response = requests.get(&#39;http://www.jianshu.com/hello.html&#39;)
exit() if not response.status_code == requests.codes.not_found else print(&#39;404 Not Found&#39;)
</code></pre>
<h3 id="3-requests-库的进阶使用"><a href="#3-requests-库的进阶使用" class="headerlink" title="3.requests 库的进阶使用"></a><strong>3.requests 库的进阶使用</strong></h3><h4 id="1-文件上传"><a href="#1-文件上传" class="headerlink" title="(1)文件上传"></a><strong>(1)文件上传</strong></h4><pre><code class="hljs">import requests

files = &#123;&#39;file&#39;:open(&#39;E:\\1.png&#39;,&#39;rb&#39;)&#125;

res= requests.post(&#39;http://httpbin.org/post&#39;,files=files)
print(res.text)
</code></pre>
<h4 id="2-获取-cookies"><a href="#2-获取-cookies" class="headerlink" title="(2)获取 cookies"></a><strong>(2)获取 cookies</strong></h4><pre><code class="hljs">import requests

res = requests.get(&quot;http://www.baidu.com&quot;)
for key,value in res.cookies.items():
    print(key + &quot;=&quot; + value)
</code></pre>
<h4 id="3-会话维持"><a href="#3-会话维持" class="headerlink" title="(3)会话维持"></a><strong>(3)会话维持</strong></h4><p>这个用法非常的重要，在我们的模拟登陆的过程中是必然会用到的方法，在 CTF 的写脚本的过程中也经常会用到，所以我们稍微详细解释一下</p>
<p>我们在使用 requests.get 的时候要明确一点就是，我们每使用一个 requests.get 就相当于重新打开了一个浏览器，因此上一个 requests.get 中设置的 cookie 在下面的第二次请求中是不能同步的，我们来看下面的例子</p>
<p><strong>实例代码:</strong></p>
<pre><code class="hljs">import requests

#这里我们设置了 cookie 
requests.get(&#39;http://httpbin.org/cookies/set/number/123456789&#39;)
#我们再次发起请求，查看是否能带着我们设置的 cookie 
res = requests.get(&#39;http://httpbin.org/cookies&#39;)
print(res.text)
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&#123;
  &quot;cookies&quot;: &#123;&#125;
&#125;
</code></pre>
<p>我们发现，正如我们上面分析的，我们第一次访问设置的 cookie 并没有在第二次访问中生效，那么怎么办呢，我们有一个 session() 方法能帮助我们解决这个问题</p>
<p><strong>实例代码：</strong></p>
<pre><code class="hljs">import requests

s = requests.Session()
s.get(&#39;http://httpbin.org/cookies/set/number/123456789&#39;)
res = s.get(&#39;http://httpbin.org/cookies&#39;)
print(res.text)
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&#123;
  &quot;cookies&quot;: &#123;
    &quot;number&quot;: &quot;123456789&quot;
  &#125;
&#125;
</code></pre>
<h4 id="4-证书验证"><a href="#4-证书验证" class="headerlink" title="(4)证书验证"></a><strong>(4)证书验证</strong></h4><p>我们在访问 https 的网站的时候浏览器首先会对网站的证书进行校验，如果发现这个证书不是官方授权的话就会出现警告页面而不会继续访问该网站，对于爬虫来讲就会抛出异常，那如果我们想要让爬虫忽略证书的问题继续访问这个网站的话就要对其进行设置</p>
<h5 id="1-忽略证书验证"><a href="#1-忽略证书验证" class="headerlink" title="1.忽略证书验证"></a><strong>1.忽略证书验证</strong></h5><pre><code class="hljs">import requests

response = requests.get(&#39;https://www.heimidy.cc/&#39;,verify=False)
print(response.status_code)
</code></pre>
<p>但是此时是存在一个警告的，我们可以通过导入 urilib3 的包，并调用消除 warning 的方法来消除这个警告</p>
<pre><code class="hljs">import requests
from requests.packages import urllib3

urllib3.disable_warnings()
response = requests.get(&#39;https://www.heimidy.cc/&#39;,verify=False)
print(response.status_code)
</code></pre>
<h5 id="2-手动指定本地证书进行验证"><a href="#2-手动指定本地证书进行验证" class="headerlink" title="2.手动指定本地证书进行验证"></a><strong>2.手动指定本地证书进行验证</strong></h5><pre><code class="hljs">import requests

response = requests.get(&#39;https://www.12306.cn&#39;, cert=(&#39;/path/server.crt&#39;, &#39;/path/key&#39;))
print(response.status_code)
</code></pre>
<h4 id="5-代理设置"><a href="#5-代理设置" class="headerlink" title="(5)代理设置"></a><strong>(5)代理设置</strong></h4><p>除了常见到的 https 和 http 代理以&#x3D;以外，我们还可以使用 socks 代理，不过需要 pip 安装一个 requests[socks] 包</p>
<pre><code class="hljs">import requests

proxies = &#123;
    &quot;http&quot;:&quot;http://127.0.0.1:1080&quot;,
    &quot;https&quot;:&quot;https://127.0.0.1:1080&quot;
&#125;

res = requests.get(&quot;https://www.google.com&quot;,proxies=proxies)
print(res.status_code)
</code></pre>
<p>这里有一个疑问就是我是用 socks 代理访问 google 是失败的，会报错</p>
<p><strong>实例代码：</strong></p>
<pre><code class="hljs">import requests

proxies = &#123;
    &quot;http&quot;:&quot;socks5://127.0.0.1:1080&quot;,
    &quot;https&quot;:&quot;socks5://127.0.0.1:1080&quot;
&#125;

res = requests.get(&quot;https://www.google.com&quot;,proxies=proxies,verify=False)
print(res.status_code)
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">SSLError: SOCKSHTTPSConnectionPool(host=&#39;www.google.com&#39;, port=443): Max retries exceeded with url: / (Caused by SSLError(SSLError(&quot;bad handshake: SysCallError(-1, &#39;Unexpected EOF&#39;)&quot;)))
</code></pre>
<p>试了一些方法都没什么效果，有待以后考证</p>
<h4 id="6-超时设置"><a href="#6-超时设置" class="headerlink" title="(6)超时设置"></a><strong>(6)超时设置</strong></h4><pre><code class="hljs">import requests
from requests.exceptions import ReadTimeout
try:
    response = requests.get(&quot;http://httpbin.org/get&quot;, timeout = 0.5)
    print(response.status_code)
except ReadTimeout:
    print(&#39;Timeout&#39;)
</code></pre>
<h4 id="7-Basic-认证"><a href="#7-Basic-认证" class="headerlink" title="(7)Basic 认证"></a><strong>(7)Basic 认证</strong></h4><p><strong>实例代码一：</strong></p>
<pre><code class="hljs">import requests
from requests.auth import HTTPBasicAuth

r = requests.get(&#39;http://120.27.34.24:9001&#39;, auth=HTTPBasicAuth(&#39;user&#39;, &#39;123&#39;))
print(r.status_code)
</code></pre>
<p><strong>实例代码二：</strong></p>
<pre><code class="hljs">import requests

r = requests.get(&#39;http://120.27.34.24:9001&#39;, auth=(&#39;user&#39;, &#39;123&#39;))
print(r.status_code)
</code></pre>
<h4 id="8-异常处理"><a href="#8-异常处理" class="headerlink" title="(8)异常处理"></a><strong>(8)异常处理</strong></h4><pre><code class="hljs">import requests
from requests.exceptions import ReadTimeout, ConnectionError, RequestException
try:
    response = requests.get(&quot;http://httpbin.org/get&quot;, timeout = 0.5)
    print(response.status_code)
except ReadTimeout:
    print(&#39;Timeout&#39;)
except ConnectionError:
    print(&#39;Connection error&#39;)
except RequestException:
    print(&#39;Error&#39;)
</code></pre>
<h2 id="0X05-正则表达式"><a href="#0X05-正则表达式" class="headerlink" title="0X05 正则表达式"></a><strong>0X05 正则表达式</strong></h2><h3 id="1-什么是正则表达式"><a href="#1-什么是正则表达式" class="headerlink" title="1.什么是正则表达式"></a><strong>1.什么是正则表达式</strong></h3><p>正则表达式是对字符串进行操作的一种逻辑公式，用事先定义好的一些特定的字符，以及这些字符的组合，组成一个规则字符串，用这个规则字符串去表达对字符串的一种过滤的逻辑，在python 中使用过re 库来实现</p>
<h3 id="2-常见的匹配模式"><a href="#2-常见的匹配模式" class="headerlink" title="2.常见的匹配模式"></a><strong>2.常见的匹配模式</strong></h3><p><img src="https://picture-1253331270.cos.ap-beijing.myqcloud.com/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%801.png" srcset="/img/loading.gif" lazyload alt="此处输入图片的描述"></p>
<h3 id="3-re-match"><a href="#3-re-match" class="headerlink" title="3.re.match"></a><strong>3.re.match</strong></h3><pre><code class="hljs">re.match(pattern, string, flags=0)
</code></pre>
<h4 id="1-常规匹配"><a href="#1-常规匹配" class="headerlink" title="(1)常规匹配"></a><strong>(1)常规匹配</strong></h4><p>span() 方法是返回匹配的范围，group() 是返回匹配的结果</p>
<p><strong>实例代码：</strong></p>
<pre><code class="hljs">import re

content = &#39;Hello 123 4567 World_This is a Regex Demo&#39;
res = re.match(&#39;^\w&#123;5&#125;\s\d&#123;3&#125;\s\d&#123;4&#125;\s\w&#123;10&#125;.*Demo$&#39;,content)
print(res.span())
print(res.group())
</code></pre>
<h4 id="2-泛匹配"><a href="#2-泛匹配" class="headerlink" title="(2)泛匹配"></a><strong>(2)泛匹配</strong></h4><pre><code class="hljs">import re

content = &#39;Hello 123 4567 World_This is a Regex Demo&#39;
res = re.match(&#39;^Hello.*Demo$&#39;,content)
print(res.span())
print(res.group())
</code></pre>
<h4 id="3-匹配具体内容"><a href="#3-匹配具体内容" class="headerlink" title="(3)匹配具体内容"></a><strong>(3)匹配具体内容</strong></h4><p>我们如果想匹配具体的内容，我们可以用小括号将其括起来</p>
<pre><code class="hljs">import re

content = &#39;Hello 1234567 World_This is a Regex Demo&#39;
res = re.match(&#39;^Hello\s(\d+)\s.*Demo$&#39;,content)
print(res.span(1))
print(res.group(1))
</code></pre>
<h4 id="4-贪婪与非贪婪模式"><a href="#4-贪婪与非贪婪模式" class="headerlink" title="(4)贪婪与非贪婪模式"></a><strong>(4)贪婪与非贪婪模式</strong></h4><p>所谓贪婪模式指的就是<code>.*</code> 会匹配尽可能多的字符，我们来看下面的例子</p>
<p><strong>实例代码：</strong></p>
<pre><code class="hljs">import re

content = &#39;Hello 1234567 World_This is a Regex Demo&#39;
res = re.match(&#39;^He.*(\d+).*Demo$&#39;,content)
print(res.span(1))
print(res.group(1))
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">(12, 13)
7
</code></pre>
<p>我们的本意是想匹配 1234567 这个字符串，但是实际上我们只匹配到了 7 ，因为<code>.*</code>默认的贪婪模式将123456匹配掉了，那么为了解决这个问题，我们可以使用<code>？</code> 去消除非贪婪模式</p>
<p><strong>实例代码：</strong></p>
<pre><code class="hljs">import re

content = &#39;Hello 1234567 World_This is a Regex Demo&#39;
res = re.match(&#39;^He.*?(\d+).*Demo$&#39;,content)
print(res.span(1))
print(res.group(1))
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">(6, 13)
1234567
</code></pre>
<h4 id="5-匹配模式"><a href="#5-匹配模式" class="headerlink" title="(5)匹配模式"></a><strong>(5)匹配模式</strong></h4><p>匹配模式是用来解决一些细节问题的，比如匹配中的是否区分大小写、是否能匹配换行符等</p>
<p><strong>实例代码：</strong></p>
<pre><code class="hljs">import re

content = &#39;&#39;&#39;Hello 1234567 World_This is 

a Regex Demo&#39;&#39;&#39;

res = re.match(&#39;^He.*?(\d+).*Demo$&#39;,content,re.S)
print(res.span(1))
print(res.group(1))
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">(6, 13)
1234567
</code></pre>
<p>可以发现我们的 <code>.*</code> 本来是不能匹配换行符的，但是我们使用了 re.S 的模式以后就可以正常匹配了</p>
<h4 id="6-转义字符"><a href="#6-转义字符" class="headerlink" title="(6)转义字符"></a>(6)转义字符</h4><p>如果在待匹配字符串中出现了正则表达式中的特殊字符，我们要对其进行转义操作</p>
<pre><code class="hljs">import re

content = &#39;price is $5.00&#39;
res = re.match(&#39;price is \$5\.00&#39;, content)
print(res.group())
</code></pre>
<h3 id="4-re-search"><a href="#4-re-search" class="headerlink" title="4.re.search"></a><strong>4.re.search</strong></h3><p>我们上面介绍的 re.match 有一个弊端就是它只能从开头开始匹配，也就是说如果我们的正则不匹配第一个字符那么是无法匹配中间的字符的，所以我们还有一个武器叫  re.search，它会扫描整个字符串并返回第一个成功的匹配。</p>
<p><strong>实例代码：</strong></p>
<pre><code class="hljs">import re

content = &#39;Extra stings Hello 1234567 World_This is a Regex Demo Extra stings&#39;
res = re.search(&#39;Hello.*?(\d+).*?Demo&#39;, content)
print(res.group(1))
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">1234567 
</code></pre>
<p>因为这个特性能大大减少我们写正则的难度，因此，我们在能用 search 的情况下就不要用 match </p>
<h4 id="匹配练习："><a href="#匹配练习：" class="headerlink" title="匹配练习："></a><strong>匹配练习：</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">import re

html = &#39;&#39;&#39;&lt;div id=&quot;songs-list&quot;&gt;
    &lt;h2 class=&quot;title&quot;&gt;经典老歌&lt;/h2&gt;
    &lt;p class=&quot;introduction&quot;&gt;
        经典老歌列表
    &lt;/p&gt;
    &lt;ul id=&quot;list&quot; class=&quot;list-group&quot;&gt;
        &lt;li data-view=&quot;2&quot;&gt;一路上有你&lt;/li&gt;
        &lt;li data-view=&quot;7&quot;&gt;
            &lt;a href=&quot;/2.mp3&quot; singer=&quot;任贤齐&quot;&gt;沧海一声笑&lt;/a&gt;
        &lt;/li&gt;
        &lt;li data-view=&quot;4&quot; class=&quot;active&quot;&gt;
            &lt;a href=&quot;/3.mp3&quot; singer=&quot;齐秦&quot;&gt;往事随风&lt;/a&gt;
        &lt;/li&gt;
        &lt;li data-view=&quot;6&quot;&gt;&lt;a href=&quot;/4.mp3&quot; singer=&quot;beyond&quot;&gt;光辉岁月&lt;/a&gt;&lt;/li&gt;
        &lt;li data-view=&quot;5&quot;&gt;&lt;a href=&quot;/5.mp3&quot; singer=&quot;陈慧琳&quot;&gt;记事本&lt;/a&gt;&lt;/li&gt;
        &lt;li data-view=&quot;5&quot;&gt;
            &lt;a href=&quot;/6.mp3&quot; singer=&quot;邓丽君&quot;&gt;&lt;i class=&quot;fa fa-user&quot;&gt;&lt;/i&gt;但愿人长久&lt;/a&gt;
        &lt;/li&gt;
    &lt;/ul&gt;
&lt;/div&gt;&#39;&#39;&#39;

res = re.search(&#39;&lt;li.*?/2\.mp3.*?singer=&quot;(.*?)&quot;&gt;(.*?)&lt;/a&gt;&#39;,html,re.S)
print(res.group(1),res.group(2))
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">任贤齐 沧海一声笑
</code></pre>
<h3 id="5-re-findall"><a href="#5-re-findall" class="headerlink" title="5.re.findall"></a><strong>5.re.findall</strong></h3><p>与之前两个不同的是 re.findall 搜会索字符串，并以列表形式返回全部能匹配的子串。</p>
<h4 id="匹配练习一："><a href="#匹配练习一：" class="headerlink" title="匹配练习一："></a><strong>匹配练习一：</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">import re

html = &#39;&#39;&#39;&lt;div id=&quot;songs-list&quot;&gt;
    &lt;h2 class=&quot;title&quot;&gt;经典老歌&lt;/h2&gt;
    &lt;p class=&quot;introduction&quot;&gt;
        经典老歌列表
    &lt;/p&gt;
    &lt;ul id=&quot;list&quot; class=&quot;list-group&quot;&gt;
        &lt;li data-view=&quot;2&quot;&gt;一路上有你&lt;/li&gt;
        &lt;li data-view=&quot;7&quot;&gt;
            &lt;a href=&quot;/2.mp3&quot; singer=&quot;任贤齐&quot;&gt;沧海一声笑&lt;/a&gt;
        &lt;/li&gt;
        &lt;li data-view=&quot;4&quot; class=&quot;active&quot;&gt;
            &lt;a href=&quot;/3.mp3&quot; singer=&quot;齐秦&quot;&gt;往事随风&lt;/a&gt;
        &lt;/li&gt;
        &lt;li data-view=&quot;6&quot;&gt;&lt;a href=&quot;/4.mp3&quot; singer=&quot;beyond&quot;&gt;光辉岁月&lt;/a&gt;&lt;/li&gt;
        &lt;li data-view=&quot;5&quot;&gt;&lt;a href=&quot;/5.mp3&quot; singer=&quot;陈慧琳&quot;&gt;记事本&lt;/a&gt;&lt;/li&gt;
        &lt;li data-view=&quot;5&quot;&gt;
            &lt;a href=&quot;/6.mp3&quot; singer=&quot;邓丽君&quot;&gt;但愿人长久&lt;/a&gt;
        &lt;/li&gt;
    &lt;/ul&gt;
&lt;/div&gt;&#39;&#39;&#39;

res = re.findall(&#39;&lt;li.*?href=&quot;(.*?)&quot;.*?singer=&quot;(.*?)&quot;&gt;(.*?)&lt;/a&gt;&#39;,html,re.S)
#print(res)
for i in res:
    print(i[0],i[1],i[2])
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">[(&#39;/2.mp3&#39;, &#39;任贤齐&#39;, &#39;沧海一声笑&#39;), (&#39;/3.mp3&#39;, &#39;齐秦&#39;, &#39;往事随风&#39;), (&#39;/4.mp3&#39;, &#39;beyond&#39;, &#39;光辉岁月&#39;), (&#39;/5.mp3&#39;, &#39;陈慧琳&#39;, &#39;记事本&#39;), (&#39;/6.mp3&#39;, &#39;邓丽君&#39;, &#39;但愿人长久&#39;)]
/2.mp3 任贤齐 沧海一声笑
/3.mp3 齐秦 往事随风
/4.mp3 beyond 光辉岁月
/5.mp3 陈慧琳 记事本
/6.mp3 邓丽君 但愿人长久
</code></pre>
<h4 id="匹配练习二："><a href="#匹配练习二：" class="headerlink" title="匹配练习二："></a><strong>匹配练习二：</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">import re

html = &#39;&#39;&#39;&lt;div id=&quot;songs-list&quot;&gt;
    &lt;h2 class=&quot;title&quot;&gt;经典老歌&lt;/h2&gt;
    &lt;p class=&quot;introduction&quot;&gt;
        经典老歌列表
    &lt;/p&gt;
    &lt;ul id=&quot;list&quot; class=&quot;list-group&quot;&gt;
        &lt;li data-view=&quot;2&quot;&gt;一路上有你&lt;/li&gt;
        &lt;li data-view=&quot;7&quot;&gt;
            &lt;a href=&quot;/2.mp3&quot; singer=&quot;任贤齐&quot;&gt;沧海一声笑&lt;/a&gt;
        &lt;/li&gt;
        &lt;li data-view=&quot;4&quot; class=&quot;active&quot;&gt;
            &lt;a href=&quot;/3.mp3&quot; singer=&quot;齐秦&quot;&gt;往事随风&lt;/a&gt;
        &lt;/li&gt;
        &lt;li data-view=&quot;6&quot;&gt;&lt;a href=&quot;/4.mp3&quot; singer=&quot;beyond&quot;&gt;光辉岁月&lt;/a&gt;&lt;/li&gt;
        &lt;li data-view=&quot;5&quot;&gt;&lt;a href=&quot;/5.mp3&quot; singer=&quot;陈慧琳&quot;&gt;记事本&lt;/a&gt;&lt;/li&gt;
        &lt;li data-view=&quot;5&quot;&gt;
            &lt;a href=&quot;/6.mp3&quot; singer=&quot;邓丽君&quot;&gt;但愿人长久&lt;/a&gt;
        &lt;/li&gt;
    &lt;/ul&gt;
&lt;/div&gt;&#39;&#39;&#39;

res = re.findall(&#39;&lt;li.*?&gt;\s*?(&lt;a.*?&gt;)?(\w+)(&lt;/a&gt;)?\s*?&lt;/li&gt;&#39;,html,re.S)
for i in res:
    print(i[0],i[1],i[2])
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs"> 一路上有你 
&lt;a href=&quot;/2.mp3&quot; singer=&quot;任贤齐&quot;&gt; 沧海一声笑 &lt;/a&gt;
&lt;a href=&quot;/3.mp3&quot; singer=&quot;齐秦&quot;&gt; 往事随风 &lt;/a&gt;
&lt;a href=&quot;/4.mp3&quot; singer=&quot;beyond&quot;&gt; 光辉岁月 &lt;/a&gt;
&lt;a href=&quot;/5.mp3&quot; singer=&quot;陈慧琳&quot;&gt; 记事本 &lt;/a&gt;
&lt;a href=&quot;/6.mp3&quot; singer=&quot;邓丽君&quot;&gt; 但愿人长久 &lt;/a&gt;
</code></pre>
<h3 id="6-re-sub"><a href="#6-re-sub" class="headerlink" title="6.re.sub"></a><strong>6.re.sub</strong></h3><p>该方法的作用是替换字符串中每一个匹配的子串后返回替换后的字符串</p>
<p><strong>实例代码一：</strong></p>
<pre><code class="hljs">import re

content = &#39;Extra stings Hello 1234567 World_This is a Regex Demo Extra stings&#39;
res = re.sub(&#39;\d+&#39;,&#39;K0rz3n&#39;,content)
print(res)
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">Extra stings Hello K0rz3n World_This is a Regex Demo Extra stings
</code></pre>
<p>有时候我们替换的时候需要保留原始字符串，这个时候我们就要使用正则表达式的后向引用技术</p>
<p><strong>实例代码二：</strong></p>
<pre><code class="hljs">import re

content = &#39;Extra stings Hello 1234567 World_This is a Regex Demo Extra stings&#39;
content = re.sub(&#39;(\d+)&#39;, &#39;\\1 8910&#39;, content)
print(content)
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">Extra stings Hello 1234567 890 World_This is a Regex Demo Extra stings
</code></pre>
<h3 id="7-re-compile"><a href="#7-re-compile" class="headerlink" title="7.re.compile"></a><strong>7.re.compile</strong></h3><p>该方法可以将正则表达式转换成正则表达式对象，方便我们后期的复用</p>
<p><strong>实例代码：</strong></p>
<pre><code class="hljs">import re

content = &#39;&#39;&#39;Hello 1234567 World_This
is a Regex Demo&#39;&#39;&#39;
pattern = re.compile(&#39;Hello.*Demo&#39;, re.S)
res = re.match(pattern, content)
print(res.group(0))
</code></pre>
<h3 id="8-实战练习爬取豆瓣读书"><a href="#8-实战练习爬取豆瓣读书" class="headerlink" title="8.实战练习爬取豆瓣读书"></a><strong>8.实战练习爬取豆瓣读书</strong></h3><pre><code class="hljs">import requests
import re
content = requests.get(&#39;http://book.douban.com/&#39;).text
pattern = re.compile(&#39;&lt;li.*?cover.*?href=&quot;(.*?)&quot;.*?title=&quot;(.*?)&quot;.*?more-meta.*?author&quot;&gt;(.*?)&lt;/span&gt;.*?year&quot;&gt;(.*?)&lt;/span&gt;.*?&lt;/li&gt;&#39;, re.S)
results = re.findall(pattern, content)
for result in results:
    url, name, author, date = result
    author = re.sub(&#39;\s&#39;, &#39;&#39;, author)
    date = re.sub(&#39;\s&#39;, &#39;&#39;, date)
    print(url, name, author, date)
</code></pre>
<h2 id="0X06-BeautifulSoup"><a href="#0X06-BeautifulSoup" class="headerlink" title="0X06 BeautifulSoup"></a><strong>0X06 BeautifulSoup</strong></h2><h3 id="1-什么是-BeautifulSoup"><a href="#1-什么是-BeautifulSoup" class="headerlink" title="1.什么是 BeautifulSoup"></a><strong>1.什么是 BeautifulSoup</strong></h3><p>这是一个方便的网页解析库，不用编写正则就是实现网页信息的提取</p>
<h3 id="2-常见的配合使用的解析库"><a href="#2-常见的配合使用的解析库" class="headerlink" title="2.常见的配合使用的解析库"></a><strong>2.常见的配合使用的解析库</strong></h3><p><img src="https://picture-1253331270.cos.ap-beijing.myqcloud.com/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%802.png" srcset="/img/loading.gif" lazyload alt="此处输入图片的描述"></p>
<h3 id="3-基本使用"><a href="#3-基本使用" class="headerlink" title="3.基本使用"></a><strong>3.基本使用</strong></h3><p><strong>实例代码：</strong></p>
<pre><code class="hljs">html = &quot;&quot;&quot;
&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;&lt;/head&gt;
&lt;body&gt;
&lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;
&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were
&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;,
&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and
&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;
and they lived at the bottom of a well.&lt;/p&gt;
&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;
&quot;&quot;&quot;

from bs4 import BeautifulSoup

soup = BeautifulSoup(html,&#39;lxml&#39;)
print(soup.prettify())
print(soup.title.string)
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&lt;html&gt;
 &lt;head&gt;
  &lt;title&gt;
   The Dormouse&#39;s story
  &lt;/title&gt;
 &lt;/head&gt;
 &lt;body&gt;
  &lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;
   &lt;b&gt;
    The Dormouse&#39;s story
   &lt;/b&gt;
  &lt;/p&gt;
  &lt;p class=&quot;story&quot;&gt;
   Once upon a time there were three little sisters; and their names were
   &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;
    &lt;!-- Elsie --&gt;
   &lt;/a&gt;
   ,
   &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;
    Lacie
   &lt;/a&gt;
   and
   &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;
    Tillie
   &lt;/a&gt;
   ;
and they lived at the bottom of a well.
  &lt;/p&gt;
  &lt;p class=&quot;story&quot;&gt;
   ...
  &lt;/p&gt;
 &lt;/body&gt;
&lt;/html&gt;
The Dormouse&#39;s story
</code></pre>
<h3 id="4-标签选择器"><a href="#4-标签选择器" class="headerlink" title="4.标签选择器"></a><strong>4.标签选择器</strong></h3><h4 id="1-选择元素"><a href="#1-选择元素" class="headerlink" title="(1)选择元素"></a><strong>(1)选择元素</strong></h4><p>使用soup.(点)属性标签的方式来进行选择，如果有多个符合的话只能返回第一个匹配的标签</p>
<p><strong>实例代码：</strong></p>
<pre><code class="hljs">html = &quot;&quot;&quot;
&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;&lt;/head&gt;
&lt;body&gt;
&lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;
&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were
&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;,
&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and
&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;
and they lived at the bottom of a well.&lt;/p&gt;
&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;
&quot;&quot;&quot;

from bs4 import BeautifulSoup

soup = BeautifulSoup(html,&#39;lxml&#39;)
print(soup.head)
print(soup.title)
print(soup.p)
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&lt;head&gt;&lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;&lt;/head&gt;
&lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;
&lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;
</code></pre>
<h4 id="2-获取属性"><a href="#2-获取属性" class="headerlink" title="(2)获取属性"></a><strong>(2)获取属性</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">html = &quot;&quot;&quot;
&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;&lt;/head&gt;
&lt;body&gt;
&lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;
&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were
&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;,
&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and
&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;
and they lived at the bottom of a well.&lt;/p&gt;
&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;
&quot;&quot;&quot;
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, &#39;lxml&#39;)
print(soup.p.attrs[&#39;name&#39;])
print(soup.p[&#39;name&#39;])
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">dromouse
dromouse
</code></pre>
<h4 id="3-获取内容"><a href="#3-获取内容" class="headerlink" title="(3)获取内容"></a><strong>(3)获取内容</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">html = &quot;&quot;&quot;
&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;&lt;/head&gt;
&lt;body&gt;
&lt;p clss=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;
&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were
&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;,
&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and
&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;
and they lived at the bottom of a well.&lt;/p&gt;
&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;
&quot;&quot;&quot;
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, &#39;lxml&#39;)
print(soup.p.string)
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">The Dormouse&#39;s story
</code></pre>
<h4 id="4-嵌套选择"><a href="#4-嵌套选择" class="headerlink" title="(4)嵌套选择"></a><strong>(4)嵌套选择</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">html = &quot;&quot;&quot;
&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;&lt;/head&gt;
&lt;body&gt;
&lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;
&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were
&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;,
&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and
&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;
and they lived at the bottom of a well.&lt;/p&gt;
&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;
&quot;&quot;&quot;
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, &#39;lxml&#39;)
print(soup.head.title.string)
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">The Dormouse&#39;s story
</code></pre>
<h4 id="5-获取子孙节点"><a href="#5-获取子孙节点" class="headerlink" title="(5)获取子孙节点"></a><strong>(5)获取子孙节点</strong></h4><h5 id="1-contents"><a href="#1-contents" class="headerlink" title="1.contents"></a><strong>1.contents</strong></h5><p>这种方法是以列表形式返回标签的子节点</p>
<p><strong>实例代码：</strong></p>
<pre><code class="hljs">html = &quot;&quot;&quot;
&lt;html&gt;
    &lt;head&gt;
        &lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;
    &lt;/head&gt;
    &lt;body&gt;
        &lt;p class=&quot;story&quot;&gt;
            Once upon a time there were three little sisters; and their names were
            &lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;
                &lt;span&gt;Elsie&lt;/span&gt;
            &lt;/a&gt;
            &lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; 
            and
            &lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;
            and they lived at the bottom of a well.
        &lt;/p&gt;
        &lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;
&quot;&quot;&quot;
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, &#39;lxml&#39;)
print(soup.p.contents)
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">[&#39;\n            Once upon a time there were three little sisters; and their names were\n            &#39;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;
&lt;span&gt;Elsie&lt;/span&gt;
&lt;/a&gt;, &#39;\n&#39;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;, &#39; \n            and\n            &#39;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;, &#39;\n            and they lived at the bottom of a well.\n        &#39;]
</code></pre>
<h5 id="2-children"><a href="#2-children" class="headerlink" title="2.children"></a><strong>2.children</strong></h5><p>这种方法返回的是一个子节点的迭代器形式</p>
<p><strong>实例代码：</strong></p>
<pre><code class="hljs">html = &quot;&quot;&quot;
&lt;html&gt;
    &lt;head&gt;
        &lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;
    &lt;/head&gt;
    &lt;body&gt;
        &lt;p class=&quot;story&quot;&gt;
            Once upon a time there were three little sisters; and their names were
            &lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;
                &lt;span&gt;Elsie&lt;/span&gt;
            &lt;/a&gt;
            &lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; 
            and
            &lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;
            and they lived at the bottom of a well.
        &lt;/p&gt;
        &lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;
&quot;&quot;&quot;
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, &#39;lxml&#39;)
print(soup.p.children)
for i, child in enumerate(soup.p.children):
    print(i, child)
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&lt;list_iterator object at 0x1064f7dd8&gt;
0 
            Once upon a time there were three little sisters; and their names were
            
1 &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;
&lt;span&gt;Elsie&lt;/span&gt;
&lt;/a&gt;
2 

3 &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;
4  
            and
            
5 &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;
6 
            and they lived at the bottom of a well.
</code></pre>
<h5 id="3-descendants"><a href="#3-descendants" class="headerlink" title="3.descendants"></a><strong>3.descendants</strong></h5><p>返回子孙节点，其实和上面 children 的不同在于这个方法会再次强调一下孙子节点</p>
<p><strong>实例代码：</strong></p>
<pre><code class="hljs">html = &quot;&quot;&quot;
&lt;html&gt;
    &lt;head&gt;
        &lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;
    &lt;/head&gt;
    &lt;body&gt;
        &lt;p class=&quot;story&quot;&gt;
            Once upon a time there were three little sisters; and their names were
            &lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;
                &lt;span&gt;Elsie&lt;/span&gt;
            &lt;/a&gt;
            &lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; 
            and
            &lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;
            and they lived at the bottom of a well.
        &lt;/p&gt;
        &lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;
&quot;&quot;&quot;
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, &#39;lxml&#39;)
print(soup.p.descendants)
for i, child in enumerate(soup.p.descendants):
    print(i, child)
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&lt;generator object descendants at 0x10650e678&gt;
0 
            Once upon a time there were three little sisters; and their names were
            
1 &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;
&lt;span&gt;Elsie&lt;/span&gt;
&lt;/a&gt;
2 

3 &lt;span&gt;Elsie&lt;/span&gt;
4 Elsie
5 

6 

7 &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;
8 Lacie
9  
            and
            
10 &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;
11 Tillie
12 
            and they lived at the bottom of a well.
</code></pre>
<h4 id="6-父节点和祖先节点"><a href="#6-父节点和祖先节点" class="headerlink" title="(6)父节点和祖先节点"></a><strong>(6)父节点和祖先节点</strong></h4><h5 id="1-parent"><a href="#1-parent" class="headerlink" title="1.parent"></a><strong>1.parent</strong></h5><p><strong>实例代码：</strong></p>
<pre><code class="hljs">html = &quot;&quot;&quot;
&lt;html&gt;
    &lt;head&gt;
        &lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;
    &lt;/head&gt;
    &lt;body&gt;
        &lt;p class=&quot;story&quot;&gt;
            Once upon a time there were three little sisters; and their names were
            &lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;
                &lt;span&gt;Elsie&lt;/span&gt;
            &lt;/a&gt;
            &lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; 
            and
            &lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;
            and they lived at the bottom of a well.
        &lt;/p&gt;
        &lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;
&quot;&quot;&quot;
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, &#39;lxml&#39;)
print(soup.a.parent)
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&lt;p class=&quot;story&quot;&gt;
Once upon a time there were three little sisters; and their names were
&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;
&lt;span&gt;Elsie&lt;/span&gt;
&lt;/a&gt;
&lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; 
and
&lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;
 and they lived at the bottom of a well.
&lt;/p&gt;
</code></pre>
<h5 id="2-parents"><a href="#2-parents" class="headerlink" title="2.parents"></a><strong>2.parents</strong></h5><p>以列表的形式输出所有的祖先节点</p>
<pre><code class="hljs">html = &quot;&quot;&quot;
&lt;html&gt;
    &lt;head&gt;
        &lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;
    &lt;/head&gt;
    &lt;body&gt;
        &lt;p class=&quot;story&quot;&gt;
            Once upon a time there were three little sisters; and their names were
            &lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;
                &lt;span&gt;Elsie&lt;/span&gt;
            &lt;/a&gt;
            &lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; 
            and
            &lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;
            and they lived at the bottom of a well.
        &lt;/p&gt;
        &lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;
&quot;&quot;&quot;
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, &#39;lxml&#39;)
print(list(enumerate(soup.a.parents)))
</code></pre>
<h4 id="7-兄弟节点"><a href="#7-兄弟节点" class="headerlink" title="(7)兄弟节点"></a><strong>(7)兄弟节点</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">html = &quot;&quot;&quot;
&lt;html&gt;
    &lt;head&gt;
        &lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;
    &lt;/head&gt;
    &lt;body&gt;
        &lt;p class=&quot;story&quot;&gt;
            Once upon a time there were three little sisters; and their names were
            &lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;
                &lt;span&gt;Elsie&lt;/span&gt;
            &lt;/a&gt;
            &lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; 
            and
            &lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;
            and they lived at the bottom of a well.
        &lt;/p&gt;
        &lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;
&quot;&quot;&quot;
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, &#39;lxml&#39;)
print(list(enumerate(soup.a.next_siblings)))
print(list(enumerate(soup.a.previous_siblings)))
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">[(0, &#39;\n&#39;), (1, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;), (2, &#39; \n            and\n            &#39;), (3, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;), (4, &#39;\n            and they lived at the bottom of a well.\n        &#39;)]
[(0, &#39;\n            Once upon a time there were three little sisters; and their names were\n            &#39;)]
</code></pre>
<h3 id="5-标准选择器"><a href="#5-标准选择器" class="headerlink" title="5.标准选择器"></a><strong>5.标准选择器</strong></h3><p>上面我们讲述的标签选择器虽然选择速度快，但是选择的内容也是比较笼统的，在现实中很难满足我们的需求，于是我们就需要更强大的选择器帮助我们去实现</p>
<pre><code class="hljs">find_all( name , attrs , recursive , text , **kwargs )
</code></pre>
<p>可根据标签名、属性、内容查找文档</p>
<h4 id="1-name"><a href="#1-name" class="headerlink" title="(1) name"></a><strong>(1) name</strong></h4><p><strong>实例代码一：</strong></p>
<pre><code class="hljs">html=&#39;&#39;&#39;
&lt;div class=&quot;panel&quot;&gt;
    &lt;div class=&quot;panel-heading&quot;&gt;
        &lt;h4&gt;Hello&lt;/h4&gt;
    &lt;/div&gt;
    &lt;div class=&quot;panel-body&quot;&gt;
        &lt;ul class=&quot;list&quot; id=&quot;list-1&quot;&gt;
            &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;
        &lt;/ul&gt;
        &lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt;
            &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/div&gt;
&lt;/div&gt;
&#39;&#39;&#39;

from bs4 import BeautifulSoup

soup = BeautifulSoup(html,&#39;lxml&#39;)
soup.find_all(&#39;ul&#39;)
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">[&lt;ul class=&quot;list&quot; id=&quot;list-1&quot;&gt;
 &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
 &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
 &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;
 &lt;/ul&gt;, &lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt;
 &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
 &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
 &lt;/ul&gt;]
</code></pre>
<p>如果我们还想获取更里面的标签，我们可以再次对获取到的 ul 标签使用 find_all()</p>
<p><strong>实例代码二：</strong></p>
<pre><code class="hljs">html=&#39;&#39;&#39;
&lt;div class=&quot;panel&quot;&gt;
    &lt;div class=&quot;panel-heading&quot;&gt;
        &lt;h4&gt;Hello&lt;/h4&gt;
    &lt;/div&gt;
    &lt;div class=&quot;panel-body&quot;&gt;
        &lt;ul class=&quot;list&quot; id=&quot;list-1&quot;&gt;
            &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;
        &lt;/ul&gt;
        &lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt;
            &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/div&gt;
&lt;/div&gt;
&#39;&#39;&#39;

from bs4 import BeautifulSoup

soup = BeautifulSoup(html,&#39;lxml&#39;)
for i in soup.find_all(&#39;ul&#39;):
    print(i.find_all(&#39;li&#39;))
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">[&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;]
[&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;]
</code></pre>
<h4 id="2-attrs"><a href="#2-attrs" class="headerlink" title="(2)attrs"></a><strong>(2)attrs</strong></h4><p>传入想要定位的属性键值对，就能成功定位</p>
<p><strong>实例代码一：</strong></p>
<pre><code class="hljs">html=&#39;&#39;&#39;
&lt;div class=&quot;panel&quot;&gt;
    &lt;div class=&quot;panel-heading&quot;&gt;
        &lt;h4&gt;Hello&lt;/h4&gt;
    &lt;/div&gt;
    &lt;div class=&quot;panel-body&quot;&gt;
        &lt;ul class=&quot;list&quot; id=&quot;list-1&quot; name=&quot;elements&quot;&gt;
            &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;
        &lt;/ul&gt;
        &lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt;
            &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/div&gt;
&lt;/div&gt;
&#39;&#39;&#39;

from bs4 import BeautifulSoup

soup = BeautifulSoup(html,&#39;lxml&#39;)
print(soup.find_all(attrs=&#123;&#39;id&#39;:&#39;list-1&#39;&#125;))
print(soup.find_all(attrs=&#123;&#39;name&#39;:&#39;elements&#39;&#125;))
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">[&lt;ul class=&quot;list&quot; id=&quot;list-1&quot; name=&quot;elements&quot;&gt;
&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
&lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
&lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;
&lt;/ul&gt;]
[&lt;ul class=&quot;list&quot; id=&quot;list-1&quot; name=&quot;elements&quot;&gt;
&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
&lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
&lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;
&lt;/ul&gt;]
</code></pre>
<p>或者，如果 你觉得这种方式比较复杂的话我们还可以使用更加简单的直接使用等于号链接属性和值作为参数传入来定位</p>
<p><strong>实例代码二：</strong></p>
<pre><code class="hljs">html=&#39;&#39;&#39;
&lt;div class=&quot;panel&quot;&gt;
    &lt;div class=&quot;panel-heading&quot;&gt;
        &lt;h4&gt;Hello&lt;/h4&gt;
    &lt;/div&gt;
    &lt;div class=&quot;panel-body&quot;&gt;
        &lt;ul class=&quot;list&quot; id=&quot;list-1&quot; name=&quot;elements&quot;&gt;
            &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;
        &lt;/ul&gt;
        &lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt;
            &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/div&gt;
&lt;/div&gt;
&#39;&#39;&#39;

from bs4 import BeautifulSoup

soup = BeautifulSoup(html,&#39;lxml&#39;)
print(soup.find_all(id = &#39;list-1&#39;))
print(soup.find_all(class_ = &#39;panel-heading&#39;))
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">[&lt;ul class=&quot;list&quot; id=&quot;list-1&quot; name=&quot;elements&quot;&gt;
&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
&lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
&lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;
&lt;/ul&gt;]
[&lt;div class=&quot;panel-heading&quot;&gt;
&lt;h4&gt;Hello&lt;/h4&gt;
&lt;/div&gt;]
</code></pre>
<blockquote>
<p><strong>注意：</strong></p>
<p>Class 是 python 中的关键字，因此我们在写属性的时候不能直接写 classs，否则会引起歧义，所以我们改成了 class_</p>
</blockquote>
<h4 id="3-text"><a href="#3-text" class="headerlink" title="(3)text"></a><strong>(3)text</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">html=&#39;&#39;&#39;
&lt;div class=&quot;panel&quot;&gt;
    &lt;div class=&quot;panel-heading&quot;&gt;
        &lt;h4&gt;Hello&lt;/h4&gt;
    &lt;/div&gt;
    &lt;div class=&quot;panel-body&quot;&gt;
        &lt;ul class=&quot;list&quot; id=&quot;list-1&quot;&gt;
            &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;
        &lt;/ul&gt;
        &lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt;
            &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/div&gt;
&lt;/div&gt;
&#39;&#39;&#39;
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, &#39;lxml&#39;)
print(soup.find_all(text=&#39;Foo&#39;))
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">[&#39;Foo&#39;, &#39;Foo&#39;]
</code></pre>
<h4 id="4-其他"><a href="#4-其他" class="headerlink" title="(4)其他"></a><strong>(4)其他</strong></h4><p>find( name , attrs , recursive , text , **kwargs )<br>find_all() 返回所有元素，而find()返回单一元素</p>
<p>find_parents() find_parent()<br>find_parents()返回所有祖先节点，find_parent()返回直接父节点。</p>
<p>find_next_siblings() find_next_sibling()<br>find_next_siblings()返回后面所有兄弟节点，find_next_sibling()返回后面第一个兄弟节点。</p>
<p>find_previous_siblings() find_previous_sibling()<br>find_previous_siblings()返回前面所有兄弟节点，find_previous_sibling()返回前面第一个兄弟节点。</p>
<p>find_all_next() find_next()<br>find_all_next()返回节点后所有符合条件的节点, find_next()返回第一个符合条件的节点</p>
<p>find_all_previous() 和 find_previous()<br>find_all_previous()返回节点后所有符合条件的节点, find_previous()返回第一个符合条件的节点</p>
<h3 id="6-CSS选择器"><a href="#6-CSS选择器" class="headerlink" title="6.CSS选择器"></a><strong>6.CSS选择器</strong></h3><h4 id="1-基本使用"><a href="#1-基本使用" class="headerlink" title="(1)基本使用"></a><strong>(1)基本使用</strong></h4><p>通过select()直接传入CSS选择器即可完成选择</p>
<p><strong>实例代码一：</strong></p>
<pre><code class="hljs">html=&#39;&#39;&#39;
&lt;div class=&quot;panel&quot;&gt;
    &lt;div class=&quot;panel-heading&quot;&gt;
        &lt;h4&gt;Hello&lt;/h4&gt;
    &lt;/div&gt;
    &lt;div class=&quot;panel-body&quot;&gt;
        &lt;ul class=&quot;list&quot; id=&quot;list-1&quot;&gt;
            &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;
        &lt;/ul&gt;
        &lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt;
            &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/div&gt;
&lt;/div&gt;
&#39;&#39;&#39;

from bs4 import BeautifulSoup

soup = BeautifulSoup(html,&#39;lxml&#39;)
print(soup.select(&#39;.panel-heading&#39;))
print(soup.select(&#39;#list-1&#39;))
print(soup.select(&#39;li&#39;))
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">[&lt;div class=&quot;panel-heading&quot;&gt;
&lt;h4&gt;Hello&lt;/h4&gt;
&lt;/div&gt;]
[&lt;ul class=&quot;list&quot; id=&quot;list-1&quot;&gt;
&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
&lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
&lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;
&lt;/ul&gt;]
[&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;]
</code></pre>
<p><strong>实例代码二：</strong></p>
<pre><code class="hljs">html=&#39;&#39;&#39;
&lt;div class=&quot;panel&quot;&gt;
    &lt;div class=&quot;panel-heading&quot;&gt;
        &lt;h4&gt;Hello&lt;/h4&gt;
    &lt;/div&gt;
    &lt;div class=&quot;panel-body&quot;&gt;
        &lt;ul class=&quot;list&quot; id=&quot;list-1&quot;&gt;
            &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;
        &lt;/ul&gt;
        &lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt;
            &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/div&gt;
&lt;/div&gt;
&#39;&#39;&#39;
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, &#39;lxml&#39;)
for ul in soup.select(&#39;ul&#39;):
    print(ul.select(&#39;li&#39;))
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">[&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;]
[&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;]
</code></pre>
<h4 id="2-获取属性-1"><a href="#2-获取属性-1" class="headerlink" title="(2)获取属性"></a><strong>(2)获取属性</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">html=&#39;&#39;&#39;
&lt;div class=&quot;panel&quot;&gt;
    &lt;div class=&quot;panel-heading&quot;&gt;
        &lt;h4&gt;Hello&lt;/h4&gt;
    &lt;/div&gt;
    &lt;div class=&quot;panel-body&quot;&gt;
        &lt;ul class=&quot;list&quot; id=&quot;list-1&quot;&gt;
            &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;
        &lt;/ul&gt;
        &lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt;
            &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/div&gt;
&lt;/div&gt;
&#39;&#39;&#39;
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, &#39;lxml&#39;)
for ul in soup.select(&#39;ul&#39;):
    print(ul[&#39;id&#39;])
    print(ul.attrs[&#39;id&#39;])
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">list-1
list-1
list-2
list-2
</code></pre>
<h4 id="3-获取内容-1"><a href="#3-获取内容-1" class="headerlink" title="(3)获取内容"></a><strong>(3)获取内容</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">html=&#39;&#39;&#39;
&lt;div class=&quot;panel&quot;&gt;
    &lt;div class=&quot;panel-heading&quot;&gt;
        &lt;h4&gt;Hello&lt;/h4&gt;
    &lt;/div&gt;
    &lt;div class=&quot;panel-body&quot;&gt;
        &lt;ul class=&quot;list&quot; id=&quot;list-1&quot;&gt;
            &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;
        &lt;/ul&gt;
        &lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt;
            &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;
            &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/div&gt;
&lt;/div&gt;
&#39;&#39;&#39;
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, &#39;lxml&#39;)
for li in soup.select(&#39;li&#39;):
    print(li.get_text())
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">Foo
Bar
Jay
Foo
Bar
</code></pre>
<h2 id="0X07-PyQuery"><a href="#0X07-PyQuery" class="headerlink" title="0X07 PyQuery"></a><strong>0X07 PyQuery</strong></h2><p>PyQuery 是另一个比较强大的网页解析库，语法完全从 jQuery 迁移过来，所以对于熟悉 JQuery 的开发人员来说是非常好的选择</p>
<h3 id="1-初始化"><a href="#1-初始化" class="headerlink" title="1.初始化"></a><strong>1.初始化</strong></h3><h4 id="1-字符串初始化"><a href="#1-字符串初始化" class="headerlink" title="(1)字符串初始化"></a><strong>(1)字符串初始化</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">html = &#39;&#39;&#39;
&lt;div&gt;
    &lt;ul&gt;
         &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt;
         &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;
         &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
         &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
         &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;
     &lt;/ul&gt;
 &lt;/div&gt;
&#39;&#39;&#39;
from pyquery import PyQuery as pq

doc = pq(html)
print(doc(&#39;li&#39;))
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt;
&lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;
</code></pre>
<h4 id="2-URL初始化"><a href="#2-URL初始化" class="headerlink" title="(2)URL初始化"></a><strong>(2)URL初始化</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">from pyquery import PyQuery as pq

doc = pq(url=&#39;http://www.baidu.com&#39;)
print(doc(&#39;head&#39;))
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&lt;head&gt;&lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html;charset=utf-8&quot;/&gt;&lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=Edge&quot;/&gt;&lt;meta content=&quot;always&quot; name=&quot;referrer&quot;/&gt;&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;http://s1.bdstatic.com/r/www/cache/bdorz/baidu.min.css&quot;/&gt;&lt;title&gt;ç¾åº¦ä¸ä¸ï¼ä½ å°±ç¥é&lt;/title&gt;&lt;/head&gt;
</code></pre>
<h4 id="3-文件初始化"><a href="#3-文件初始化" class="headerlink" title="(3)文件初始化"></a><strong>(3)文件初始化</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">from pyquery import PyQuery as pq
doc = pq(filename=&#39;demo.html&#39;)
print(doc(&#39;li&#39;))
</code></pre>
<h3 id="2-基本CSS选择器"><a href="#2-基本CSS选择器" class="headerlink" title="2.基本CSS选择器"></a><strong>2.基本CSS选择器</strong></h3><p><strong>实例代码：</strong></p>
<pre><code class="hljs">html = &#39;&#39;&#39;
&lt;div id=&quot;container&quot;&gt;
    &lt;ul class=&quot;list&quot;&gt;
         &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt;
         &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;
         &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
         &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
         &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;
     &lt;/ul&gt;
 &lt;/div&gt;
&#39;&#39;&#39;
from pyquery import PyQuery as pq
doc = pq(html)
print(doc(&#39;#container .list li&#39;))
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt;
&lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;
</code></pre>
<h3 id="3-查找元素"><a href="#3-查找元素" class="headerlink" title="3.查找元素"></a><strong>3.查找元素</strong></h3><h4 id="1-子元素"><a href="#1-子元素" class="headerlink" title="(1)子元素"></a><strong>(1)子元素</strong></h4><p><strong>实例代码一：</strong></p>
<pre><code class="hljs">html = &#39;&#39;&#39;
&lt;div id=&quot;container&quot;&gt;
    &lt;ul class=&quot;list&quot;&gt;
         &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt;
         &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;
         &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
         &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
         &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;
     &lt;/ul&gt;
 &lt;/div&gt;
&#39;&#39;&#39;

from pyquery import PyQuery as pq

doc = pq(html)
li = doc(&#39;.list&#39;).find(&#39;li&#39;)
print(li)
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt;
&lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;
     
</code></pre>
<p>当然，除了使用 find 方法以外，我们还能使用 children 方法</p>
<p><strong>实例代码二：</strong></p>
<pre><code class="hljs">html = &#39;&#39;&#39;
&lt;div id=&quot;container&quot;&gt;
    &lt;ul class=&quot;list&quot;&gt;
         &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt;
         &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;
         &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
         &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
         &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;
     &lt;/ul&gt;
 &lt;/div&gt;
&#39;&#39;&#39;

from pyquery import PyQuery as pq

doc = pq(html)
items = doc(&#39;.list&#39;)
lis = items.children(&#39;.active&#39;)
print(lis)
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
         &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
         
</code></pre>
<h4 id="2-父元素"><a href="#2-父元素" class="headerlink" title="(2)父元素"></a><strong>(2)父元素</strong></h4><p><strong>实例代码一：</strong></p>
<pre><code class="hljs">html = &#39;&#39;&#39;
&lt;div id=&quot;container&quot;&gt;
    &lt;ul class=&quot;list&quot;&gt;
         &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt;
         &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;
         &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
         &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
         &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;
     &lt;/ul&gt;
 &lt;/div&gt;
&#39;&#39;&#39;

from pyquery import PyQuery as pq

doc = pq(html)
items = doc(&#39;.list&#39;)
container = items.parent()
print(container)
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&lt;div id=&quot;container&quot;&gt;
    &lt;ul class=&quot;list&quot;&gt;
         &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt;
         &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;
         &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
         &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
         &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;
     &lt;/ul&gt;
 &lt;/div&gt;
</code></pre>
<p>使用 parent() 是返回直接父节点，但是使用 parents()能返回全部的父节点</p>
<p><strong>实例代码二：</strong></p>
<pre><code class="hljs">html = &#39;&#39;&#39;
&lt;div class=&quot;wrap&quot;&gt;
    &lt;div id=&quot;container&quot;&gt;
        &lt;ul class=&quot;list&quot;&gt;
             &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt;
             &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;
         &lt;/ul&gt;
     &lt;/div&gt;
 &lt;/div&gt;
&#39;&#39;&#39;
from pyquery import PyQuery as pq
doc = pq(html)
items = doc(&#39;.list&#39;)
parents = items.parents(&#39;.wrap&#39;)
print(parents)
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&lt;div class=&quot;wrap&quot;&gt;
    &lt;div id=&quot;container&quot;&gt;
        &lt;ul class=&quot;list&quot;&gt;
             &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt;
             &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;
         &lt;/ul&gt;
     &lt;/div&gt;
 &lt;/div&gt;
</code></pre>
<h4 id="3-兄弟节点"><a href="#3-兄弟节点" class="headerlink" title="(3)兄弟节点"></a><strong>(3)兄弟节点</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">html = &#39;&#39;&#39;
&lt;div class=&quot;wrap&quot;&gt;
    &lt;div id=&quot;container&quot;&gt;
        &lt;ul class=&quot;list&quot;&gt;
             &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt;
             &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;
         &lt;/ul&gt;
     &lt;/div&gt;
 &lt;/div&gt;
&#39;&#39;&#39;
from pyquery import PyQuery as pq
doc = pq(html)
li = doc(&#39;.list .item-0.active&#39;)
print(li.siblings(&#39;.active&#39;))
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
</code></pre>
<h3 id="4-遍历"><a href="#4-遍历" class="headerlink" title="4.遍历"></a><strong>4.遍历</strong></h3><p><strong>实例代码：</strong></p>
<pre><code class="hljs">html = &#39;&#39;&#39;
&lt;div class=&quot;wrap&quot;&gt;
    &lt;div id=&quot;container&quot;&gt;
        &lt;ul class=&quot;list&quot;&gt;
             &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt;
             &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;
         &lt;/ul&gt;
     &lt;/div&gt;
 &lt;/div&gt;
&#39;&#39;&#39;

from pyquery import PyQuery as pq

doc = pq(html)
lis = doc(&#39;li&#39;).items()
for i in lis:
    print(i)
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt;
             
&lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;
             
&lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
             
&lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
             
&lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;
</code></pre>
<h3 id="5-获取信息"><a href="#5-获取信息" class="headerlink" title="5.获取信息"></a><strong>5.获取信息</strong></h3><h4 id="1-获取属性"><a href="#1-获取属性" class="headerlink" title="(1)获取属性"></a><strong>(1)获取属性</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">html = &#39;&#39;&#39;
&lt;div class=&quot;wrap&quot;&gt;
    &lt;div id=&quot;container&quot;&gt;
        &lt;ul class=&quot;list&quot;&gt;
             &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt;
             &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;
         &lt;/ul&gt;
     &lt;/div&gt;
 &lt;/div&gt;
&#39;&#39;&#39;

from pyquery import PyQuery as pq

doc = pq(html)
a = doc(&#39;.list .item-0.active a&#39;)
print(a.attr.href)
print(a.attr(&#39;href&#39;))
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">link3.html
link3.html
</code></pre>
<h4 id="2-获取文本"><a href="#2-获取文本" class="headerlink" title="(2)获取文本"></a><strong>(2)获取文本</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">html = &#39;&#39;&#39;
&lt;div class=&quot;wrap&quot;&gt;
    &lt;div id=&quot;container&quot;&gt;
        &lt;ul class=&quot;list&quot;&gt;
             &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt;
             &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;
         &lt;/ul&gt;
     &lt;/div&gt;
 &lt;/div&gt;
&#39;&#39;&#39;
from pyquery import PyQuery as pq
doc = pq(html)
a = doc(&#39;.item-0.active a&#39;)
print(a.text())
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">third item
</code></pre>
<h4 id="3-获取-HTML"><a href="#3-获取-HTML" class="headerlink" title="(3)获取 HTML"></a><strong>(3)获取 HTML</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">html = &#39;&#39;&#39;
&lt;div class=&quot;wrap&quot;&gt;
    &lt;div id=&quot;container&quot;&gt;
        &lt;ul class=&quot;list&quot;&gt;
             &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt;
             &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;
         &lt;/ul&gt;
     &lt;/div&gt;
 &lt;/div&gt;
&#39;&#39;&#39;
from pyquery import PyQuery as pq
doc = pq(html)
li = doc(&#39;.item-0.active&#39;)
print(li.html())
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;
</code></pre>
<h3 id="6-DOM操作"><a href="#6-DOM操作" class="headerlink" title="6.DOM操作"></a><strong>6.DOM操作</strong></h3><h4 id="1-addClass、removeClass"><a href="#1-addClass、removeClass" class="headerlink" title="(1)addClass、removeClass"></a><strong>(1)addClass、removeClass</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">html = &#39;&#39;&#39;
&lt;div class=&quot;wrap&quot;&gt;
    &lt;div id=&quot;container&quot;&gt;
        &lt;ul class=&quot;list&quot;&gt;
             &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt;
             &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;
         &lt;/ul&gt;
     &lt;/div&gt;
 &lt;/div&gt;
&#39;&#39;&#39;
from pyquery import PyQuery as pq
doc = pq(html)
li = doc(&#39;.item-0.active&#39;)
print(li)
li.removeClass(&#39;active&#39;)
print(li)
li.addClass(&#39;active&#39;)
print(li)
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
             
&lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
             
&lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
</code></pre>
<h4 id="2-attr、css"><a href="#2-attr、css" class="headerlink" title="(2)attr、css"></a><strong>(2)attr、css</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">html = &#39;&#39;&#39;
&lt;div class=&quot;wrap&quot;&gt;
    &lt;div id=&quot;container&quot;&gt;
        &lt;ul class=&quot;list&quot;&gt;
             &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt;
             &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;
             &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;
         &lt;/ul&gt;
     &lt;/div&gt;
 &lt;/div&gt;
&#39;&#39;&#39;
from pyquery import PyQuery as pq
doc = pq(html)
li = doc(&#39;.item-0.active&#39;)
print(li)
li.attr(&#39;name&#39;,&#39;link&#39;)
print(li)
li.css(&#39;front-size&#39;,&#39;14px&#39;)
print(li)
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
             
&lt;li class=&quot;item-0 active&quot; name=&quot;link&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
             
&lt;li class=&quot;item-0 active&quot; name=&quot;link&quot; style=&quot;front-size: 14px&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
</code></pre>
<h4 id="3-remove"><a href="#3-remove" class="headerlink" title="(3)remove"></a><strong>(3)remove</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">html = &#39;&#39;&#39;
&lt;div class=&quot;wrap&quot;&gt;
    Hello, World
    &lt;p&gt;This is a paragraph.&lt;/p&gt;
 &lt;/div&gt;
&#39;&#39;&#39;

from pyquery import PyQuery as pq

doc = pq(html)
wrap = doc(&#39;.wrap&#39;)
print(wrap.text())
wrap.find(&#39;p&#39;).remove()
print(wrap.text())
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">Hello, World
This is a paragraph.
Hello, World
</code></pre>
<h4 id="4-其他-1"><a href="#4-其他-1" class="headerlink" title="(4)其他"></a><strong>(4)其他</strong></h4><p><a target="_blank" rel="noopener" href="https://pyquery.readthedocs.io/en/latest/api.html">https://pyquery.readthedocs.io/en/latest/api.html</a></p>
<h2 id="0X08-Selenium"><a href="#0X08-Selenium" class="headerlink" title="0X08 Selenium"></a><strong>0X08 Selenium</strong></h2><p>该函数库可以配合各种浏览器引擎以及 phantomJS 进行自动化测试工作，主要是为了解决 JS 动态渲染页面无法直接抓取的问题</p>
<h3 id="1-基本使用-1"><a href="#1-基本使用-1" class="headerlink" title="1.基本使用"></a><strong>1.基本使用</strong></h3><p><strong>实例代码：</strong></p>
<pre><code class="hljs">from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.wait import WebDriverWait

browser = webdriver.Chrome()
try:
    browser.get(&#39;https://www.baidu.com&#39;)
    input = browser.find_element_by_id(&#39;kw&#39;)
    input.send_keys(&#39;Python&#39;)
    input.send_keys(Keys.ENTER)
    wait = WebDriverWait(browser, 10)
    wait.until(EC.presence_of_element_located((By.ID, &#39;content_left&#39;)))
    print(browser.current_url)
    print(browser.get_cookies())
    print(browser.page_source)
finally:
    browser.close()
</code></pre>
<h3 id="2-声明对象"><a href="#2-声明对象" class="headerlink" title="2.声明对象"></a><strong>2.声明对象</strong></h3><pre><code class="hljs">from selenium import webdriver

browser = webdriver.Chrome()
browser = webdriver.Firefox()
browser = webdriver.Edge()
browser = webdriver.PhantomJS()
browser = webdriver.Safari()
</code></pre>
<h3 id="3-访问页面"><a href="#3-访问页面" class="headerlink" title="3.访问页面"></a><strong>3.访问页面</strong></h3><pre><code class="hljs">from selenium import webdriver

browser = webdriver.Chrome()
browser.get(&quot;https://www.baidu.com&quot;)
print(browser.page_source)
browser.close()
</code></pre>
<h3 id="4-查找元素"><a href="#4-查找元素" class="headerlink" title="4.查找元素"></a><strong>4.查找元素</strong></h3><h4 id="1-查找单个元素"><a href="#1-查找单个元素" class="headerlink" title="(1)查找单个元素"></a><strong>(1)查找单个元素</strong></h4><p><strong>实例代码一：</strong></p>
<pre><code class="hljs">from selenium import webdriver

browser = webdriver.Chrome()
browser.get(&#39;https://www.taobao.com&#39;)
input_first = browser.find_element_by_id(&#39;q&#39;)
input_second = browser.find_element_by_css_selector(&#39;#q&#39;)
input_third = browser.find_element_by_xpath(&#39;//*[@id=&quot;q&quot;]&#39;)
print(input_first, input_second, input_third)
browser.close()
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&lt;selenium.webdriver.remote.webelement.WebElement (session=&quot;06448c4d710820390f33d87c3033a505&quot;, element=&quot;0.38405353494037175-1&quot;)&gt; &lt;selenium.webdriver.remote.webelement.WebElement (session=&quot;06448c4d710820390f33d87c3033a505&quot;, element=&quot;0.38405353494037175-1&quot;)&gt; &lt;selenium.webdriver.remote.webelement.WebElement (session=&quot;06448c4d710820390f33d87c3033a505&quot;, element=&quot;0.38405353494037175-1&quot;)&gt;
</code></pre>
<blockquote>
<p><strong>补充：</strong></p>
<p>除此之外还有一些查找元素的方法，如下</p>
<pre><code class="hljs">find_element_by_name
find_element_by_xpath
find_element_by_link_text
find_element_by_partial_link_text
find_element_by_tag_name
find_element_by_class_name
find_element_by_css_selector
</code></pre>
</blockquote>
<p><strong>实例代码二：</strong></p>
<pre><code class="hljs">from selenium import webdriver
from selenium.webdriver.common.by import By

browser = webdriver.Chrome()
browser.get(&#39;https://www.taobao.com&#39;)
input_first = browser.find_element(By.ID, &#39;q&#39;)
print(input_first)
browser.close()
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&lt;selenium.webdriver.remote.webelement.WebElement (session=&quot;1f209c0d11551c40d9d20ad964fef244&quot;, element=&quot;0.07914603542731591-1&quot;)&gt;
</code></pre>
<h4 id="2-查找多个元素"><a href="#2-查找多个元素" class="headerlink" title="(2)查找多个元素"></a><strong>(2)查找多个元素</strong></h4><p><strong>实例代码一：</strong></p>
<pre><code class="hljs">from selenium import webdriver

browser = webdriver.Chrome()
browser.get(&#39;https://www.taobao.com&#39;)
lis = browser.find_elements_by_css_selector(&#39;.service-bd li&#39;)
print(lis)
browser.close()
</code></pre>
<p><strong>实例代码二：</strong></p>
<pre><code class="hljs">from selenium import webdriver
from selenium.webdriver.common.by import By

browser = webdriver.Chrome()
browser.get(&#39;https://www.taobao.com&#39;)
lis = browser.find_elements(By.CSS_SELECTOR, &#39;.service-bd li&#39;)
print(lis)
browser.close()
</code></pre>
<blockquote>
<p><strong>补充：</strong></p>
<p>除了上面的查找方法，查找多个元素还有下面的一些常见的方法：</p>
<p>find_elements_by_name find_elements_by_xpath<br>find_elements_by_link_text find_elements_by_partial_link_text<br>find_elements_by_tag_name find_elements_by_class_name<br>find_elements_by_css_selector</p>
</blockquote>
<h4 id="3-元素的交互操作"><a href="#3-元素的交互操作" class="headerlink" title="(3)元素的交互操作"></a><strong>(3)元素的交互操作</strong></h4><p>我们可以对获取的元素调用交互方法</p>
<p><strong>实例代码：</strong></p>
<pre><code class="hljs">from selenium import webdriver
import time

browser = webdriver.Chrome()
browser.get(&quot;http://www.taobao.com&quot;)
input = browser.find_element_by_id(&#39;q&#39;)
input.send_keys(&#39;iphone&#39;)
time.sleep(1)
input.clear()
input.send_keys(&#39;ipad&#39;)
button = browser.find_element_by_class_name(&#39;btn-search&#39;)
button.click()
</code></pre>
<blockquote>
<p><strong>补充：</strong></p>
<p><strong>官方文档:</strong><br><a target="_blank" rel="noopener" href="http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.remote.webelement">http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.remote.webelement</a></p>
</blockquote>
<h4 id="4-交互动作"><a href="#4-交互动作" class="headerlink" title="(4)交互动作"></a><strong>(4)交互动作</strong></h4><p>将动作附加到动作链中串行执行，这是我们使用 selenium 去模拟键鼠操作的非常常用的东西</p>
<p><strong>实例代码：</strong></p>
<pre><code class="hljs">from selenium import webdriver
from selenium.webdriver import ActionChains

browser = webdriver.Chrome()
url = &#39;http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable&#39;
browser.get(url)
browser.switch_to.frame(&#39;iframeResult&#39;)
source = browser.find_element_by_css_selector(&#39;#draggable&#39;)
target = browser.find_element_by_css_selector(&#39;#droppable&#39;)
actions = ActionChains(browser)
actions.drag_and_drop(source, target)
actions.perform()
</code></pre>
<blockquote>
<p><strong>补充：</strong></p>
<p><strong>官方文档:</strong><br><a target="_blank" rel="noopener" href="http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.common.action_chains">http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.common.action_chains</a></p>
<p><strong>ActionChains方法列表</strong><br>click(on_element&#x3D;None) ——单击鼠标左键<br>click_and_hold(on_element&#x3D;None) ——点击鼠标左键，不松开<br>context_click(on_element&#x3D;None) ——点击鼠标右键<br>double_click(on_element&#x3D;None) ——双击鼠标左键<br>drag_and_drop(source, target) ——拖拽到某个元素然后松开<br>drag_and_drop_by_offset(source, xoffset, yoffset) ——拖拽到某个坐标然后松开<br>key_down(value, element&#x3D;None) ——按下某个键盘上的键<br>key_up(value, element&#x3D;None) ——松开某个键<br>move_by_offset(xoffset, yoffset) ——鼠标从当前位置移动到某个坐标<br>move_to_element(to_element) ——鼠标移动到某个元素<br>move_to_element_with_offset(to_element, xoffset, yoffset)<br>——移动到距某个元素（左上角坐标）多少距离的位置<br>perform() ——执行链中的所有动作<br>release(on_element&#x3D;None) ——在某个元素位置松开鼠标左键<br>send_keys(*keys_to_send) ——发送某个键到当前焦点的元素<br>send_keys_to_element(element, *keys_to_send) ——发送某个键到指定元素</p>
</blockquote>
<h4 id="5-执行JavaScript"><a href="#5-执行JavaScript" class="headerlink" title="(5)执行JavaScript"></a><strong>(5)执行JavaScript</strong></h4><p>当我们找不到现成的 api 的时候，我们可以使用 js 来帮助我们实现一些动作，比如进度条的拖拽等</p>
<p><strong>实例代码：</strong></p>
<pre><code class="hljs">from selenium import webdriver

browser = webdriver.Chrome()
browser.get(&#39;https://www.zhihu.com/explore&#39;)
browser.execute_script(&#39;window.scrollTo(0, document.body.scrollHeight)&#39;)
browser.execute_script(&#39;alert(&quot;To Bottom&quot;)&#39;)
browser.close()
</code></pre>
<h3 id="5-获取元素信息"><a href="#5-获取元素信息" class="headerlink" title="5.获取元素信息"></a><strong>5.获取元素信息</strong></h3><h4 id="1-获取属性-1"><a href="#1-获取属性-1" class="headerlink" title="(1)获取属性"></a><strong>(1)获取属性</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">from selenium import webdriver
from selenium.webdriver import ActionChains

browser = webdriver.Chrome()
url = &#39;https://www.zhihu.com/explore&#39;
browser.get(url)
logo = browser.find_element_by_id(&#39;zh-top-link-logo&#39;)
print(logo)
print(logo.get_attribute(&#39;class&#39;))
browser.close()
</code></pre>
<h4 id="2-获取文本值"><a href="#2-获取文本值" class="headerlink" title="(2)获取文本值"></a><strong>(2)获取文本值</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">from selenium import webdriver

browser = webdriver.Chrome()
url = &#39;https://www.zhihu.com/explore&#39;
browser.get(url)
input = browser.find_element_by_class_name(&#39;zu-top-add-question&#39;)
print(input.text)
browser.close()
</code></pre>
<h4 id="3-获取ID、位置、标签名、大小"><a href="#3-获取ID、位置、标签名、大小" class="headerlink" title="(3)获取ID、位置、标签名、大小"></a><strong>(3)获取ID、位置、标签名、大小</strong></h4><p><strong>实例代码：</strong></p>
<pre><code class="hljs">from selenium import webdriver

browser = webdriver.Chrome()
url = &#39;https://www.zhihu.com/explore&#39;
browser.get(url)
input = browser.find_element_by_class_name(&#39;zu-top-add-question&#39;)
print(input.id)
print(input.location)
print(input.tag_name)
print(input.size)
browser.close()
</code></pre>
<h3 id="6-Frame-操作"><a href="#6-Frame-操作" class="headerlink" title="6.Frame 操作"></a><strong>6.Frame 操作</strong></h3><p>如果出现 frame 或者 iframe 我们必须要进入这个区域才能进行操作</p>
<p><strong>实例代码：</strong></p>
<pre><code class="hljs">import time
from selenium import webdriver
from selenium.common.exceptions import NoSuchElementException

browser = webdriver.Chrome()
url = &#39;http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable&#39;
browser.get(url)
browser.switch_to.frame(&#39;iframeResult&#39;)
source = browser.find_element_by_css_selector(&#39;#draggable&#39;)
print(source)
try:
    logo = browser.find_element_by_class_name(&#39;logo&#39;)
except NoSuchElementException:
    print(&#39;NO LOGO&#39;)
finally:
    browser.close()
browser.switch_to.parent_frame()
logo = browser.find_element_by_class_name(&#39;logo&#39;)
print(logo)
print(logo.text)
</code></pre>
<h3 id="7-等待"><a href="#7-等待" class="headerlink" title="7.等待"></a><strong>7.等待</strong></h3><h4 id="1-隐式等待"><a href="#1-隐式等待" class="headerlink" title="(1)隐式等待"></a><strong>(1)隐式等待</strong></h4><p>这个方法是针对网页中的 ajax 请求设计的，当 webdriver 查找元素或元素并没有立即出现的时候(可能还需要后期的 ajax 请求)，隐式等待将等待一段时间再查找 DOM，默认的时间是0</p>
<p><strong>实例代码：</strong></p>
<pre><code class="hljs">from selenium import webdriver

browser = webdriver.Chrome()
browser.implicitly_wait(10)
browser.get(&#39;https://www.zhihu.com/explore&#39;)
input = browser.find_element_by_class_name(&#39;zu-top-add-question&#39;)
print(input)
browser.close()
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&lt;selenium.webdriver.remote.webelement.WebElement (session=&quot;a607aed65e614d975de7a1273522ff3a&quot;, element=&quot;0.7555513559347986-1&quot;)&gt;
</code></pre>
<h4 id="2-显式等待"><a href="#2-显式等待" class="headerlink" title="(2)显式等待"></a><strong>(2)显式等待</strong></h4><p>显示等待会设置一个条件和一个最长等待时间，如果在这个最长等待时间内条件还是没有成立才会抛出异常</p>
<p><strong>实例代码：</strong></p>
<pre><code class="hljs">from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

browser = webdriver.Chrome()
browser.get(&#39;https://www.taobao.com/&#39;)
wait = WebDriverWait(browser, 10)
input = wait.until(EC.presence_of_element_located((By.ID, &#39;q&#39;)))
button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, &#39;.btn-search&#39;)))
print(input, button)
browser.close()
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">&lt;selenium.webdriver.remote.webelement.WebElement (session=&quot;c3730876d29127a08cdcdb54a664600f&quot;, element=&quot;0.37070383186598255-1&quot;)&gt; &lt;selenium.webdriver.remote.webelement.WebElement (session=&quot;c3730876d29127a08cdcdb54a664600f&quot;, element=&quot;0.37070383186598255-2&quot;)&gt;
</code></pre>
<blockquote>
<p><strong>补充：</strong></p>
</blockquote>
<p><strong>常见的判断条件：</strong></p>
<blockquote>
<p>title_is 标题是某内容<br>title_contains 标题包含某内容<br>presence_of_element_located 元素加载出，传入定位元组，如(By.ID, ‘p’)<br>visibility_of_element_located 元素可见，传入定位元组<br>visibility_of 可见，传入元素对象<br>presence_of_all_elements_located 所有元素加载出<br>text_to_be_present_in_element 某个元素文本包含某文字<br>text_to_be_present_in_element_value 某个元素值包含某文字<br>frame_to_be_available_and_switch_to_it frame加载并切换<br>invisibility_of_element_located 元素不可见<br>element_to_be_clickable 元素可点击<br>staleness_of 判断一个元素是否仍在DOM，可判断页面是否已经刷新<br>element_to_be_selected 元素可选择，传元素对象<br>element_located_to_be_selected 元素可选择，传入定位元组<br>element_selection_state_to_be 传入元素对象以及状态，相等返回True，否则返回False<br>element_located_selection_state_to_be 传入定位元组以及状态，相等返回True，否则返回False<br>alert_is_present 是否出现Alert</p>
<p><strong>官方文档：</strong><br><a target="_blank" rel="noopener" href="http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.support.expected_conditions">http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.support.expected_conditions</a></p>
</blockquote>
<h3 id="8-前进后退"><a href="#8-前进后退" class="headerlink" title="8.前进后退"></a><strong>8.前进后退</strong></h3><p><strong>实例代码：</strong></p>
<pre><code class="hljs">from selenium import webdriver 

browser = webdriver.Chrome()
browser.get(&quot;http://www.baidu.com&quot;)
browser.get(&quot;http://www.taobao.com&quot;)
browser.get(&quot;http://www.zhihu.com&quot;)
browser.back()
browser.forward()
browser.close()
</code></pre>
<h3 id="9-Cookies"><a href="#9-Cookies" class="headerlink" title="9.Cookies"></a><strong>9.Cookies</strong></h3><p><strong>实例代码：</strong></p>
<pre><code class="hljs">from selenium import webdriver

browser = webdriver.Chrome()
browser.get(&#39;http://www.baidu.com&#39;)
print(browser.get_cookies())
browser.add_cookie(&#123;&#39;name&#39;:&#39;Tom&#39;,&#39;pass&#39;:&#39;123456&#39;,&#39;value&#39;: &#39;germey&#39;&#125;)
print(browser.get_cookies())
browser.delete_all_cookies()
print(browser.get_cookies())
browser.close()
</code></pre>
<h3 id="10-选项卡操作"><a href="#10-选项卡操作" class="headerlink" title="10.选项卡操作"></a><strong>10.选项卡操作</strong></h3><p><strong>实例代码：</strong></p>
<pre><code class="hljs">from selenium import webdriver
import time

browser = webdriver.Chrome()
browser.get(&#39;http://www.baidu.com&#39;)
browser.execute_script(&#39;window.open()&#39;)
print(browser.window_handles)
browser.switch_to.window(browser.window_handles[1])
browser.get(&#39;http://www.taobao.com&#39;)
time.sleep(1)
browser.switch_to.window(browser.window_handles[0])
browser.get(&#39;http://httpbin.org&#39;)
browser.close()
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">[&#39;CDwindow-3FCC47842DFF6841B4C86EE72CB7DB93&#39;, &#39;CDwindow-CCFA4494DE4B6C99494BE87524153E4E&#39;]
</code></pre>
<h3 id="11-异常处理"><a href="#11-异常处理" class="headerlink" title="11.异常处理"></a><strong>11.异常处理</strong></h3><p><strong>实例代码：</strong></p>
<pre><code class="hljs">from selenium import webdriver
from selenium.common.exceptions import TimeoutException, NoSuchElementException

browser = webdriver.Chrome()
try:
    browser.get(&#39;https://www.baidu.com&#39;)
except TimeoutException:
    print(&#39;Time Out&#39;)
try:
    browser.find_element_by_id(&#39;hello&#39;)
except NoSuchElementException:
    print(&#39;No Element&#39;)
finally:
    browser.close()
</code></pre>
<p><strong>运行结果：</strong></p>
<pre><code class="hljs">No Element
</code></pre>
<blockquote>
<p><strong>补充：</strong></p>
<p>官方文档：详细文档：<a target="_blank" rel="noopener" href="http://selenium-python.readthedocs.io/api.html#module-selenium.common.exceptions">http://selenium-python.readthedocs.io/api.html#module-selenium.common.exceptions</a></p>
</blockquote>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E5%A4%87%E5%BF%98/" class="category-chain-item">备忘</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E7%88%AC%E8%99%AB/" class="print-no-link">#爬虫</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Python3 爬虫知识梳理(基础篇)</div>
      <div>http://example.com/2019/05/03/Python3 爬虫知识梳理(基础篇)/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>May 3, 2019</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="NC - Non-commercial">
                    <i class="iconfont icon-cc-nc"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="SA - Share-alike">
                    <i class="iconfont icon-cc-sa"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2019/05/07/python3%20%E7%88%AC%E8%99%AB%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86(%E5%AE%9E%E6%88%98%E7%AF%87)/" title="Python3 爬虫知识梳理(实战篇)">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Python3 爬虫知识梳理(实战篇)</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2019/04/20/JAVA%20%E6%B3%9B%E5%9E%8B%E3%80%81%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E6%8A%80%E6%9C%AF%E8%A6%81%E7%82%B9%E6%A2%B3%E7%90%86/" title="JAVA 泛型、动态代理技术要点梳理">
                        <span class="hidden-mobile">JAVA 泛型、动态代理技术要点梳理</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
